/* description: Parses end executes mathematical expressions. */
/* Accepts complex arrays, combination of numbers, CELLS, and RANGES, with and without $ reference */
/* every time a new function is added, update the formula_function_definitions.functionsSupported array of the formula bar */
/* (latest)-moving Names and NameRangesUp for recognition before Cell IDs - this way a name like Rev2[2011] is accepted */
/* remember to remove the console.logs in parser.js */

/* Real names accept letters, numbers and underscores and must have at least one number or letter somewhere in the string */
/* http://stackoverflow.com/questions/576196/regular-expression-allow-letters-numbers-and-spaces-with-at-least-one-letter */
/* a real name cannot be in isolation but only recognized next to another, checks will be done in the name column and row to match REGEX but parser only understands NAME as [{IDENTIFIER_START} 0-9]+'['[{IDENTIFIER_START} 0-9]+']' */

/* from this version there are also mixed ranges */





/*
 * lexical grammar
 * ===============
 *
 * This section defines the lexer rules for our formula parser. The rules are checked from top to bottom, so order is import
 * here!
 *
 * The lexer plays a major role in the parser as it helps the parser itself to overcome the limitations of LALR(1) in some spots
 * in the grammar.
 *
 * As an aside, note that some of the Unicode regexes are included as we want to be able to parse anything that is
 * copy-pasted from inside our own grid display, even when we apply alternative formatting there for display purposes.
 */

%lex


%options backtrack_lexer


/*
 * Remember that in `jison`, when the `lexer.option.flex` has not been set (i.e. we get default behaviour),
 * we get a hit on the first matching regex, so the order of the tokenization regexes below is
 * very important.
 *
 * `option.flex` would perform an exhaustive scan of all regexes, thus trying to find the
 * longest match every time. We do not want that in our lexical scanner!
 */

%{
    /*
     * This chunk is included in the lexer action code at the very start of that method.
     *
     * `YY_START` is defined then, `YYSTATE` is not! `yy` and `yy_` are also available here.
     */
    var s, s2, s3;
    var rv, rv2, e_offset, col, row, len, value;
    var match, match2;

    //console.log("lexer action: ", yy, yy_, this, yytext, YY_START, $avoiding_name_collisions);

    var parser = yy.parser;
%}


/*
 * We have several 'lexer states', all of which are defined here: `%x` means it's an _exclusive_ lexer state, while
 * JISON considers `%s` states to be _inclusive_, i.e. states which include the set of unmarked lexer rules alongside
 * the ones that are marked up as belonging to the given state.
 */

%x INLINE_COMMENT
%x PARSE_MODE_DETECTION



/*
 * WARNING
 * -------
 *
 * When you use these regex 'macros' below, be aware that JISON surrounds them with () braces
 * to ensure they always act as a single element.
 *
 * Hence, for example, JISON transforms the lexer regex
 *
 *      ({ID}(\.{ID})*)(\s*\()
 *
 * into this JS regex
 *
 *      /^(?:(([A-Za-z_][A-Za-z0-9_]*)(\.([A-Za-z_][A-Za-z0-9_]*))*)(\s*\())/
 *
 * which will return more `matches[]` elements than you would expect from the lexer regex itself
 * as the regex element
 *
 *      {ID}
 *
 * itself expands to a (...)-surrounded regex element
 *
 *      ([A-Za-z_][A-Za-z0-9_]*)
 *
 * therefore placing the part matching
 *
 *      (\s*\()
 *
 * at `matches[]` index `[5]` rather than the originally expected `[3]`, so that input
 *
 *      MIN(x, y)
 *
 * will have the example regex match the part
 *
 *      MIN(
 *
 * as intended, while producing a `this.matches[]` array with the following content:
 *
 *      this.matches = [
 *          "MIN(",
 *          "MIN",
 *          "MIN",
 *          undefined,
 *          undefined,
 *          "("
 *      ]
 *
 * (note the `undefined` entries at `[3] `and `[4]` in there!), while input
 *
 *      A.B.C(x)
 *
 * will have the example regex match the part
 *
 *      A.B.C(
 *
 * as intended, while producing a `this.matches[]` array with the following content:
 *
 *      this.matches = ["A.B.C(", "A.B.C", "A", ".C", "C", "("]
 */


ASCII_LETTER                        [a-zA-Z]

// Unicode literal chars set: 
//   ªµºÀ-ÖØ-öø-ˁˆ-ˑˠ-ˤˬˮͰ-ʹͶͷͺ-ͽͿΆΈ-ΊΌΎ-ΡΣ-ϵϷ-ҁҊ-ԯԱ-Ֆՙա-ևא-תװ-ײؠ-يٮٯٱ-ۓەۥۦۮۯۺ-ۼۿܐܒ-ܯݍ-ޥޱߊ-ߪߴߵߺࠀ-ࠕࠚࠤࠨࡀ-ࡘࢠ-ࢲऄ-हऽॐक़-ॡॱ-ঀঅ-ঌএঐও-নপ-রলশ-হঽৎড়ঢ়য়-ৡৰৱਅ-ਊਏਐਓ-ਨਪ-ਰਲਲ਼ਵਸ਼ਸਹਖ਼-ੜਫ਼ੲ-ੴઅ-ઍએ-ઑઓ-નપ-રલળવ-હઽૐૠૡଅ-ଌଏଐଓ-ନପ-ରଲଳଵ-ହଽଡ଼ଢ଼ୟ-ୡୱஃஅ-ஊஎ-ஐஒ-கஙசஜஞடணதந-பம-ஹௐఅ-ఌఎ-ఐఒ-నప-హఽౘౙౠౡಅ-ಌಎ-ಐಒ-ನಪ-ಳವ-ಹಽೞೠೡೱೲഅ-ഌഎ-ഐഒ-ഺഽൎൠൡൺ-ൿඅ-ඖක-නඳ-රලව-ෆก-ะาำเ-ๆກຂຄງຈຊຍດ-ທນ-ຟມ-ຣລວສຫອ-ະາຳຽເ-ໄໆໜ-ໟༀཀ-ཇཉ-ཬྈ-ྌက-ဪဿၐ-ၕၚ-ၝၡၥၦၮ-ၰၵ-ႁႎႠ-ჅჇჍა-ჺჼ-ቈቊ-ቍቐ-ቖቘቚ-ቝበ-ኈኊ-ኍነ-ኰኲ-ኵኸ-ኾዀዂ-ዅወ-ዖዘ-ጐጒ-ጕጘ-ፚᎀ-ᎏᎠ-Ᏼᐁ-ᙬᙯ-ᙿᚁ-ᚚᚠ-ᛪᛮ-ᛸᜀ-ᜌᜎ-ᜑᜠ-ᜱᝀ-ᝑᝠ-ᝬᝮ-ᝰក-ឳៗៜᠠ-ᡷᢀ-ᢨᢪᢰ-ᣵᤀ-ᤞᥐ-ᥭᥰ-ᥴᦀ-ᦫᧁ-ᧇᨀ-ᨖᨠ-ᩔᪧᬅ-ᬳᭅ-ᭋᮃ-ᮠᮮᮯᮺ-ᯥᰀ-ᰣᱍ-ᱏᱚ-ᱽᳩ-ᳬᳮ-ᳱᳵᳶᴀ-ᶿḀ-ἕἘ-Ἕἠ-ὅὈ-Ὅὐ-ὗὙὛὝὟ-ώᾀ-ᾴᾶ-ᾼιῂ-ῄῆ-ῌῐ-ΐῖ-Ίῠ-Ῥῲ-ῴῶ-ῼⁱⁿₐ-ₜℂℇℊ-ℓℕℙ-ℝℤΩℨK-ℭℯ-ℹℼ-ℿⅅ-ⅉⅎⅠ-ↈⰀ-Ⱞⰰ-ⱞⱠ-ⳤⳫ-ⳮⳲⳳⴀ-ⴥⴧⴭⴰ-ⵧⵯⶀ-ⶖⶠ-ⶦⶨ-ⶮⶰ-ⶶⶸ-ⶾⷀ-ⷆⷈ-ⷎⷐ-ⷖⷘ-ⷞⸯ々-〇〡-〩〱-〵〸-〼ぁ-ゖゝ-ゟァ-ヺー-ヿㄅ-ㄭㄱ-ㆎㆠ-ㆺㇰ-ㇿ㐀-䶵一-鿌ꀀ-ꒌꓐ-ꓽꔀ-ꘌꘐ-ꘟꘪꘫꙀ-ꙮꙿ-ꚝꚠ-ꛯꜗ-ꜟꜢ-ꞈꞋ-ꞎꞐ-ꞭꞰꞱꟷ-ꠁꠃ-ꠅꠇ-ꠊꠌ-ꠢꡀ-ꡳꢂ-ꢳꣲ-ꣷꣻꤊ-ꤥꤰ-ꥆꥠ-ꥼꦄ-ꦲꧏꧠ-ꧤꧦ-ꧯꧺ-ꧾꨀ-ꨨꩀ-ꩂꩄ-ꩋꩠ-ꩶꩺꩾ-ꪯꪱꪵꪶꪹ-ꪽꫀꫂꫛ-ꫝꫠ-ꫪꫲ-ꫴꬁ-ꬆꬉ-ꬎꬑ-ꬖꬠ-ꬦꬨ-ꬮꬰ-ꭚꭜ-ꭟꭤꭥꯀ-ꯢ가-힣ힰ-ퟆퟋ-ퟻ豈-舘並-龎ﬀ-ﬆﬓ-ﬗיִײַ-ﬨשׁ-זּטּ-לּמּנּסּףּפּצּ-ﮱﯓ-ﴽﵐ-ﶏﶒ-ﷇﷰ-ﷻﹰ-ﹴﹶ-ﻼＡ-Ｚａ-ｚｦ-ﾾￂ-ￇￊ-ￏￒ-ￗￚ-ￜА-Яа-я

UNICODE_LETTER_RANGE                [\p{Alphabetic}]

IDENTIFIER_START                    [{UNICODE_LETTER_RANGE}_]
LABEL_START                         [{UNICODE_LETTER_RANGE}\p{Number}]
IDENTIFIER_LAST                     [{LABEL_START}_]
IDENTIFIER_MIDDLE                   [{IDENTIFIER_LAST}.]
LABEL_MIDDLE                        [{IDENTIFIER_LAST} ]
DOLLAR                              [\u0024]
WHITESPACE                          [\s\r\n]

NON_OPERATOR_CHAR                   [{WHITESPACE}{IDENTIFIER_LAST}]





/*
    https://github.com/mishoo/UglifyJS2/blob/master/lib/parse.js#L121
*/
ID                                  [{IDENTIFIER_START}][{IDENTIFIER_LAST}]*
DOTTED_ID                           [{IDENTIFIER_START}](?:[{IDENTIFIER_MIDDLE}]*[{IDENTIFIER_LAST}])?
WORD                                [{IDENTIFIER_LAST}]+
WORDS                               [{IDENTIFIER_LAST}](?:[\s{IDENTIFIER_LAST}]*[{IDENTIFIER_LAST}])?
DOTTED_WORDS                        [{IDENTIFIER_LAST}](?:[\s{IDENTIFIER_MIDDLE}]*[{IDENTIFIER_LAST}])?
JSON_WORD                           [{IDENTIFIER_LAST}](?:[{IDENTIFIER_LAST}\-]*[{IDENTIFIER_LAST}])?
WORKBOOK_PREFIX                     [0-9]+[!]
PATH                                (?:"/"{DOTTED_ID})+"/"?

OPERATOR                            [^{NON_OPERATOR_CHAR}]{1,3}

// Match simple floating point values, for example `1.0`, but also `9.`, `.05` or just `7`:
BASIC_FLOATING_POINT_NUMBER         (?:[0-9]+(?:"."[0-9]*)?|"."[0-9]+)

// This marks the end of an elemental token which is not itself an operator, row or column reference or a function.
TOKEN_SENTINEL                      \s*(?:$|[^\s\.{IDENTIFIER_LAST}\(\[\{\$\@\!\'\"])
DUALIC_OPERATOR_MUST_FOLLOW         \s*(?:$|[^{NON_OPERATOR_CHAR}\.\(\[\{\$\@\!\'\"])
OPERATOR_SENTINEL                   \s*(?:$|[^{NON_OPERATOR_CHAR}])



%%

/*
 * A word on the `PARSE_MODE_DETECTION` 'hack' / We have multiple `%start` Rules
 * -----------------------------------------------------------------------------
 *
 * The `PARSE_MODE_DETECTION` mode is a parser/lexer communications hack to give us multiple start rules, i.e.
 * we use this hack as the code generator (JISON) does not support multiple `%start` rules.
 *
 * We 'hack' this feature into the grammar by setting up a start rules which first checks which start
 * rule we really desire and then goes and tweaks the input fed to the lexer (and switches to the
 * `PARSE_MODE_DETECTION` mode alongside) to help the lexer 'fake' a token which the parser can then
 * use to switch to the desired start rule.
 *
 * As the hack involves using the JISON lexer `.unput()` method at the very beginning of the parsing/lexing
 * process, the 'hack' byte which is meant to tickle the lexer as described above, lands in NEGATIVE `yylloc`
 * space. In other words: the hack does not damage the input position information of the real text/input
 * being lexed/parsed subsequently.
 *
 * The intricacies of the 'hack' involve:
 *
 * - a *grammar* subrule to set it all up, which itself does not require any lexer tokens (is 'empty') nor any
 *   look-ahead, thus allowing the parser to 'reduce' this `init_phase` rule without having had to call the
 *   lexer *yet*. This means that any parser action code attached to this `init_phase` rule will execute
 *   before the lexer is demanded to deliver any tokens.
 *
 * - us pushing a special character value as a prefix of the lexed input via `.unput()`: this character is
 *   later recognized by the lexer and produces a special token which is used to direct the parser
 *   towards the desired 'start rule'.
 *
 * The crux here is that we do not want any look-ahead or other lexer tokenization activity before we have
 * been able to set up the context for switching to a particular start rule.
 *
 * To protect against the 'magic characters' `\u0001 .. \u0003` occurring in (possibly malicious/illegal) input, we use a
 * lexer mode which will only be used at the very start of the parse process: `PARSE_MODE_DETECTION`.
 */

<PARSE_MODE_DETECTION>"\u0001"
        %{
            this.popState();
            return 'CELLREF_PARSE_MODE';
        %}

<PARSE_MODE_DETECTION>"\u0002"
        %{
            this.popState();
            return 'RANGEREF_PARSE_MODE';
        %}

<PARSE_MODE_DETECTION>"\u0003"
        %{
            this.popState();
            return 'VALUE_PARSE_MODE';
        %}

/*
 * Catch all other possible initial input characters, make sure we do not consume them and
 * process the input in the default parse mode: `INITIAL`
 */
<PARSE_MODE_DETECTION>.
        %{
            this.popState();
            /*
             * When we did not observe one of the special character codes at the forefront of our
             * input stream then we will parsing the entire input in the default mode, i.e. as a formula.
             *
             * Therefore, let the previous lexer state (should be `INITIAL`) process this bit instead;
             * do not consume the matched input.
             *
             * **WARNING**: you might think this would be easily accomplished using the lexer.reject()
             * call like this:
             *
             *     this.reject();
             *
             * but `reject()` only works as expected _as long as you do NOT switch lexer states_!
             *
             * Some understanding of the lexer internals is required here: when you call `reject()`, the
             * lexer will simply test the input against the next regex in the current set. The key here
             * is _the current set_: when the lexer is required to produce a token, it will construct
             * a _regex set_ given the _current lexer state_.
             *
             * What we need here is the lexer retrying matching the same input after we changed the
             * lexer state above when we called:
             *
             *     this.popState();
             *
             * The way to accomplish this is to 'push back' the matched content into the input buffer using
             * `.unput()` and then signal the lexer that we matched nothing by returning no token at all:
             *
             *      return false;
             *
             * That `return false` will make sure the lexer considers this action as 'complete' (by
             * us `return`ing from the lexer), while the boolean `false` tells the lexer it will need
             * to run another round in order to provide its caller with a 'real' lexed token.
             *
             *
             * ### For the technically inquisitive
             *
             * The crux is us employing the side effects of the jison lexer engine,
             * more specifically this bit, where I'd like you to take notice of
             * the recursive nature of the `.lex()` method in here, plus the fact that `.next()`
             * will call `._currentRules()` each time it is invoked (while this is a very much
             * reduced and somewhat paraphrased extract of the original):
             *
             *      // generated by jison-lex...
             *      parser.lexer = {
             *          ...,
             *          next: function () {
             *              ...
             *              var match, token, rule_under_test;
             *              var rules = this._currentRules();
             *              for (var i = 0; i < rules.length; i++) {
             *                  rule_under_test = this.rules[rules[i]];
             *                  match = this._input.match(rule_under_test);
             *                  ...
             *                  if (match) {
             *                      // exec the matching lexer action code:
             *                      token = this.test_match(match, rule_under_test);
             *
             *                      // stay in this loop when .reject() was called,
             *                      // otherwise we'll run with this match:
             *                      if (!this.rejected) break;
             *                  }
             *              }
             *              if (match) {
             *                  ...
             *                  if (token !== false) {
             *                      return token;
             *                  }
             *                  // else: this is a lexer rule which consumes input
             *                  //       without producing a token (e.g. whitespace)
             *                  return false;
             *              }
             *              ...
             *          },
             *
             *          // return next match that has a token
             *          lex: function lex() {
             *              var r = this.next();
             *              if (r) {
             *                  return r;
             *              } else {
             *                  return this.lex();
             *              }
             *          },
             *
             *          // produce the lexer rule set which is active
             *          // for the currently active lexer condition state
             *          _currentRules: function _currentRules() {
             *              ...
             *              return this.conditions[...].rules;
             *          },
             *
             *          ...
             *
             *          conditions: {
             *              "PARSE_MODE_DETECTION": {
             *                  rules: [
             *                      0, 1, 2, 3, 4
             *                  ],
             *                  inclusive: false
             *              },
             *              ...
             *              "INITIAL": {
             *                  rules: [
             *                      5, 6, 7, 8, 9,
             *                      ...
             *                  ],
             *                  inclusive: true
             *              }
             *          }
             *      };
             *
             */
            this.unput(this.matches[0]);
            return false;
        %}

<PARSE_MODE_DETECTION><<EOF>>
        %{
            this.popState();
            // let the previous lexer state process that EOF for real...
            return false;
        %}





/*
 * And here our lexer rule sets starts for real...
 * -----------------------------------------------
 *
 * We try to match the big important chunks as soon as possible, so they end up as the first lexer rules here:
 * we first check for function names, label names, constants and currency identifiers as those would consume the
 * largest number of input characters on a match; the _operators_ (such as `+` and `*`) are matched next as those
 * are both simple to match and only consume 1-3 characters.
 *
 * Separate 'lexer states' concern themselves with consuming 'inline comments' (a feature not available in Excel
 * but which is very handy once the formulas in your cells start to grow beyond an 'entry level' complexity) and
 * the 'JSON database/filtering' subexpressions: for more on those, see the grammar section addressing
 * data sources.
 */




// Recognize any function constant, with optional dotted sections, as a string which is followed by a `()` empty argument list, e.g. `PI()`

{DOTTED_ID}(\s*\(\s*\))
        %{
            /*
             * lookup this blurb: it MAY be an Excel constant posing as a function (e.g. `PI()`).
             *
             * Note that this is really another kind of lexical hack as here we include
             * a part of the GRAMMAR KNOWLEDGE in the lexer itself:
             *
             * since we 'know' now that the blurb `\1` is followed by an open brace `(`, we
             * can be certain that this is a function identifier and nothing else
             * that may have the same 'name', e.g. constant `E` or `PI` (or for very wide
             * spreadsheets: `ABS`).
             *
             * > ### Note
             * >
             * > the braces in the regex are there so we can easily grab each bit,
             * > and in particular that very last bit: it will ALWAYS be pushed back
             * > into the lexer queue as that bit is our 'additional look-ahead' at
             * > work!
             */
            // console.log("looking up functional constant in symbol table: ", yytext, this, this.matches);
            /*
             * **WARNING**: take heed of the comment further above regarding the `ID` and `WORD`
             * lexer regex 'macros' and JISON's behaviour regarding those!
             *
             * Hence we should be able to pick up the `(` at the end at `this.matches[2]`!
             */
            //this.unput(this.matches[2]);
            s = this.matches[1];
            rv = parser.getSymbol4DefinedConstant(s, FSC_FUNCTION);
            if (rv) {
                yytext = rv.value;
                switch (rv.attributes & OPCODE_MASK_FOR_FT_VALUE_TYPE) {
                default:
                    return 'CONSTANT';

                case FT_BOOLEAN:
                    if (rv.value)
                        return 'TRUE';
                    else
                        return 'FALSE';

                case FT_STRING:
                    return 'STRING';
                }
            }

            // DRY: and go test the next rule(s) on the same content:
            this.reject();
        %}


// Recognize any function ID, with optional dotted sections, as a string which is followed by a `(` open brace, e.g. `Z.DIST(`

{DOTTED_ID}(?=\s*\()
        %{
            /*
             * lookup this blurb: it MAY be a (possibly namespaced) function identifier
             * (e.g. `SUM`, `namespace.user_defined_function42`).
             *
             * When it is not, then it most probably is a cell reference with a JSON filter expression,
             * including a filter _function_.
             *
             * Note that this is really another kind of lexical hack as here we include
             * a part of the GRAMMAR KNOWLEDGE in the lexer itself:
             *
             * since we 'know' now that the blurb `\1` is followed by an open brace `(`, we
             * can be certain that this is a function identifier and nothing else
             * that may have the same 'name', e.g. constant `E` or `PI` (or for very wide
             * spreadsheets: `ABS`).
             *
             * > ### Note
             * >
             * > the braces in the regex are there so we can easily grab each bit,
             * > and in particular that very last bit: it will ALWAYS be pushed back
             * > into the lexer queue as that bit is our 'additional look-ahead' at
             * > work!
             */
            // console.log("looking up function identifier token (+ look-ahead) in symbol table: ", yytext, this, this.matches);
            /*
             * **WARNING**: take heed of the comment further above regarding the `ID` and `WORD`
             * lexer regex 'macros' and JISON's behaviour regarding those!
             *
             * Hence we should be able to pick up the `(` at the end at `this.matches[3]`!
             */
            s = yytext;
            rv = parser.getSymbol4Function(s);
            /*
             * play nasty: produce a token ID for all functions which we support directly
             * and produce a FUNCTION token (with attribute) for everyone else.
             */
            if (rv) {
                yytext = {
                    opcode: rv,
                    text: s
                };

                return 'FUNCTION';
            }

            // DRY: and go test the next rule(s) on the same content:
            this.reject();
        %}



// Check whether we have a full cell reference:

// (\$?){WORDS}\s*(\$?)\[\s*(\$?){WORDS}\s*\]



// Check whether we have a full cell reference (this time it is recognized by the '$' pin in the middle, rather than the square brackets):

// (\$?){WORDS}\s*(\$){WORDS}



// Check whether we have a string which is always followed by a square bracket `[` or `]` or another `$`:
// these are strong hints that we may be dealing with *part of* a cell reference, possibly using row / column labels.

// (\$?){WORDS}(?=\s*[\[\]\$])


// Recognize a complete basic cell reference, with optional '$' pinned row and/or column.

// (\$?)([{UNICODE_LETTER_RANGE}]+)\s*(\$?)([0-9]+)(?={DUALIC_OPERATOR_MUST_FOLLOW})


// (\$?){WORDS}(?={DUALIC_OPERATOR_MUST_FOLLOW})




// Recognize a complete basic cell reference, with optional '$' pinned row and/or column.

{WORKBOOK_PREFIX}?{DOLLAR}?[{LABEL_MIDDLE}]+'['{DOLLAR}?[{LABEL_MIDDLE}]+']'[:]{WORKBOOK_PREFIX}?{DOLLAR}?[{LABEL_MIDDLE}]+'['{DOLLAR}?[{LABEL_MIDDLE}]+']'
		{ if (parser.isValidCellRange(yytext)) { yytext = parser.convertYYTEXTtoRangeRefObject(yytext); return 'RANGEREF'; } else { this.reject(); } }

{WORKBOOK_PREFIX}?{DOLLAR}?[{LABEL_MIDDLE}]+'['{DOLLAR}?[{LABEL_MIDDLE}]+']'[:]{WORKBOOK_PREFIX}?{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+
		{ if (parser.isValidCellRange(yytext)) { yytext = parser.convertYYTEXTtoRangeRefObject(yytext); return 'RANGEREF'; } else { this.reject(); } }

{WORKBOOK_PREFIX}?{DOLLAR}?[{LABEL_MIDDLE}]+'['{DOLLAR}?[{LABEL_MIDDLE}]+']'
		{ if (parser.isValidCellRef(yytext)) { yytext = parser.convertYYTEXTtoCellRefObject(yytext); return 'CELLREF'; } else { this.reject(); } }

// below are the original symmetrical combinations (e.g., $ - : $ - , - $ : - $, - - : - -)

{WORKBOOK_PREFIX}?{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+[:]{WORKBOOK_PREFIX}?{DOLLAR}?[{LABEL_MIDDLE}]+'['{DOLLAR}?[{LABEL_MIDDLE}]+']'
		{ if (parser.isValidCellRange(yytext)) { yytext = parser.convertYYTEXTtoRangeRefObject(yytext); return 'RANGEREF'; } else { this.reject(); } }

{WORKBOOK_PREFIX}?{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+[:]{WORKBOOK_PREFIX}?{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+
		{ if (parser.isValidCellRange(yytext)) { yytext = parser.convertYYTEXTtoRangeRefObject(yytext); return 'RANGEREF'; } else { this.reject(); } }

{WORKBOOK_PREFIX}?{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+
		{ if (parser.isValidCellRef(yytext)) { yytext = parser.convertYYTEXTtoCellRefObject(yytext); return 'CELLREF'; } else { this.reject(); } }

{SOURCE}{WORKBOOK_PREFIX}{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+
		{
            if (parser.isValidCellRef(yytext)) {
                yytext = parser.convertYYTEXTtoCellRefObject(yytext);
                return 'CELLREF';
            }
            else
            {
                this.reject();
            }
        }

{SOURCE}{WORKBOOK_STRING_PREFIX}{DOLLAR}?[{UNICODE_LETTER_RANGE}]+{DOLLAR}?[0-9]+
		{
            if (parser.isValidCellRef(yytext)) {
                yytext = parser.convertYYTEXTtoCellRefObject(yytext);
                return 'CELLREF';
            }
            else
            {
                this.reject();
            }
        }


// Recognize an ID, with optional dotted sections, which is NOT followed by a '[' bracket, '$' or open brace '('.
// Matching any of those tail characters would be illegal for a predefined constant as those indicate
// this would be a function or cell reference element instead.

{DOTTED_ID}(?={DUALIC_OPERATOR_MUST_FOLLOW})
        %{
            /*
             * lookup this blurb: it MAY be a namespaced constant (`LN10`, `namespace.user_defined_constant42`, `MATH.E`).
             */
            // console.log("looking up namespaced constant identifier token (+ look-ahead) in symbol table: ", yytext, this, this.matches);
            s = yytext;
            rv = parser.getSymbol4DefinedConstant(s);
            if (rv) {
                yytext = rv.value;
                switch (rv.attributes & OPCODE_MASK_FOR_FT_VALUE_TYPE) {
                default:
                    return 'CONSTANT';

                case FT_BOOLEAN:
                    if (rv.value)
                        return 'TRUE';
                    else
                        return 'FALSE';

                case FT_STRING:
                    return 'STRING';
                }
            }

            // DRY: and go test the next rule(s) on the same content:
            this.reject();
        %}



// *TODO* / *TBR*
// --------------
//
// Accept dates in US, EU, DE and many other formats when these exist and span the entire input:
//
// MM/DD/YY :: DD-MM-YY :: DD.MM.YY :: MMM DDth, YY, ...
//
// where MM can also be MMM (alphanumeric shorthand) or MMMMMM (full month name) and
// YY can also be YYYY.
//
// The date MAY be followed by a time in 12 or 24 hour format and/or a timezone. ISO formats are also
// accepted (where the timestamp is prefixed with the `T` character).
(?:[{LABEL_START}][{LABEL_START} \\\/,.:-]+)(?=\s*$)
        %{
            // TODO: parse as date (+ optional timestamp): if it is A-okay, then we have a hit.
            //
            // Else: reject.

            // DRY: and go test the next rule(s) on the same content:
            this.reject();
        %}




// Parse any 'resistor notation' numeric value, e.g. `4K7` or `2.2M`

/* see also: http://codeidol.com/community/perl/know-the-precedence-of-regular-expression-operator/14215/ */
{BASIC_FLOATING_POINT_NUMBER}[kKmMgG]|[0-9]+[kKmMgG][0-9]+
        %{
            /*
             * Numbers with Kilo, Mega or Giga, including **resistor notation**, i.e. `1K5`.
             *
             * Keep in mind that certain locations in a formula do accept 'labels'
             * which can look **exactly** like 'numbers' for pathologically-named
             * row/column labels, e.g. `2K12`.
             *
             * We use the parser to disambiguate between the two when the lexer rules
             * above haven't already dealt with this condition.
             */
            s = yytext;
            rv = s.match(/^([^kKmMgG]+)([kKmMgG])([^kKmMgG]*)$/);
            //console.log("parsing 'resistor notation' value: ", rv, s);
            switch (rv[2].toUpperCase()) {
            case "K":
                rv2 = 1E3;
                break;

            case "M":
                rv2 = 1E6;
                break;

            case "G":
                rv2 = 1E9;
                break;

            default:
                rv2 = 1;
                break;
            }
            if (rv[3].length > 0) {
                rv[1] += "." + rv[3];
            }
            // http://jsperf.com/number-vs-plus-vs-toint-vs-tofloat/26 --> parseFloat()
            s2 = parseFloat(rv[1]) * rv2;

            yytext = s2;

            // since these numbers cannot 'pose' as ROW numbers, we need not check for `INTEGER_NUMBER` suitability:
            return 'NUMBER';
        %}


{BASIC_FLOATING_POINT_NUMBER}(?:[eE][+-]?[0-9]+)?
        %{
            /*
             * Any numbers, including those in 'scientific notation', i.e. `1E5`
             *
             * Keep in mind that certain locations in a formula do accept 'labels'
             * which can look **exactly** like 'numbers' for pathologically-named
             * row / column labels, e.g. `2012`.
             *
             * We use the parser to disambiguate between the two when the lexer rules
             * above haven't already dealt with this condition.
             */

            s = yytext;
            // http://jsperf.com/number-vs-plus-vs-toint-vs-tofloat/26 --> parseFloat()
            s2 = parseFloat(s);

            yytext = s2;

            // for a number to be a floating point number, it must have a dot or an E part or be too large / small to be an integer
            if (parseInt(s, 10) !== s2) {
                return 'NUMBER';
            }
            // else:
            return 'INTEGER_NUMBER';
        %}



// quick hack to disambiguate grammar for %-modulo vs. %-percent
//
// N.B.: this is one reason why we move to a PEG-based grammar:
//       predicates are the clean & legible way to solve this type of LA(k>1) problem.
[%](?=\s*([^{IDENTIFIER_LAST}\(\s]|$))
        %{
            yytext = '%';
            return 'PERCENTAGE_OPERATOR';
        %}


{OPERATOR}
        %{
            /*
             * Check if the matched string STARTS WITH an operator in the list below.
             *
             * On the first pass, a hash table is created (and cached) to speed up matching.
             */
            if (!this.__operator_hash_table) {
                var definition_table = [
                    {
                        name: "$",
                        lexer_opcode: FKA_FIXED_ROW_OR_COLUMN_MARKER,
                        produce: function () {
                            return '$';
                        }
                    },
                    {
                        name: ":",
                        lexer_opcode: FKA_RANGE_MARKER,
                        produce: function () {
                            return ':';
                        }
                    },
                    {
                        name: "...",                   /* .. and ... equal : */
                        lexer_opcode: FKA_RANGE_MARKER,
                        produce: function () {
                            return ':';
                        }
                    },
                    {
                        name: "..",                    /* .. and ... equal : */
                        lexer_opcode: FKA_RANGE_MARKER,
                        produce: function () {
                            return ':';
                        }
                    },
                    {
                        name: ",",
                        lexer_opcode: FKA_COMMA,
                        produce: function () {
                            return ',';
                        }
                    },
                    {
                        name: "/*",
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["*/"];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "(*",
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["*)"];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "{*",
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["*}"];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "#",
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["#"];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "\u203c",                                  /* ‼ */
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["!!", "\u203c" /* ‼ */];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "\u2590",                                  /* ▐ */
                        produce: function (loc) {
                            // set the end-of-comment marker for this comment and switch to parsing the comment
                            if (this.options.inline_comment_mode < this.inline_comments_monitor) {
                                this.inline_comment_end_markers = ["\u258c" /* ▌ */, "\u2590" /* ▐ */];
                                this.inline_comment_start_yylloc = parser.deepCopy(loc);
                                this.pushState('INLINE_COMMENT');
                                return false;
                            }
                            // no dice, try another!
                            this.reject();
                        }
                    },
                    {
                        name: "&&",
                        opcode: FKW_BOOLEAN_AND_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'BOOLEAN_AND_OPERATOR';
                        }
                    },
                    {
                        name: "||",
                        opcode: FKW_BOOLEAN_OR_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'BOOLEAN_OR_OPERATOR';
                        }
                    },
                    {
                        name: "&",
                        opcode: FKW_STRING_CONCATENATION_OPERATOR | FT_STRING | FU_STRING,
                        produce: function () {
                            return 'STRING_CONCATENATION_OPERATOR';
                        }
                    },
                    {
                        name: "<=",                                     // Unicode alternatives: \u22dc
                        opcode: FKW_LESS_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'LESS_OR_EQUAL';
                        }
                    },
                    {
                        name: ">=",                                     // Unicode alternatives: \u22dd
                        opcode: FKW_GREATER_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'GREATER_OR_EQUAL';
                        }
                    },
                    {
                        name: "\u2264",
                        opcode: FKW_LESS_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'LESS_OR_EQUAL';                         /* ≤ */
                        }
                    },
                    {
                        name: "\u2266",
                        opcode: FKW_LESS_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'LESS_OR_EQUAL';                         /* ≦ */
                        }
                    },
                    {
                        name: "\u2265",
                        opcode: FKW_GREATER_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'GREATER_OR_EQUAL';                      /* ≥ */
                        }
                    },
                    {
                        name: "\u2267",
                        opcode: FKW_GREATER_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'GREATER_OR_EQUAL';                      /* ≧ */
                        }
                    },
                    {
                        name: "<>",                                     // Unicode alternatives: \u2276, \u2277
                        opcode: FKW_NOT_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'NOT_EQUAL';
                        }
                    },
                    {
                        name: "!=",                                     // Unicode alternatives: \u2260
                        opcode: FKW_NOT_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'NOT_EQUAL';
                        }
                    },
                    {
                        name: "!==",
                        opcode: FKW_NOT_IDENTICAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'NOT_IDENTICAL';
                        }
                    },
                    {
                        name: "<",
                        opcode: FKW_LESS_THAN | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return '<';
                        }
                    },
                    {
                        name: ">",
                        opcode: FKW_GREATER_THAN | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return '>';
                        }
                    },
                    {
                        name: "===",
                        opcode: FKW_IS_IDENTICAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'IS_IDENTICAL';
                        }
                    },
                    {
                        name: "==",
                        opcode: FKW_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'IS_EQUAL';
                        }
                    },
                    {
                        name: "=",
                        opcode: FKW_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            // This MAY be the `=` starting a formula: mark the event for the inline comments:
                            if (this.options.inline_comment_mode > 0) {
                                if (!this.inline_comments_monitor) {
                                    this.inline_comments_monitor = this.options.inline_comment_mode + 1;
                                }
                            }
                            return '=';
                        }
                    },
                    {
                        name: "**",
                        opcode: FKW_POWER | FT_NUMBER | FU_ANY,
                        produce: function () {
                            return '^';
                        }
                    },
                    {
                        name: "*",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';
                        }
                    },
                    {
                        name: "/",
                        opcode: FKW_DIVIDE | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '/';
                        }
                    },
                    {
                        name: "-",
                        opcode: FKW_SUBTRACT | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '-';
                        }
                    },
                    {
                        name: "+",
                        opcode: FKW_ADD | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '+';
                        }
                    },
                    {
                        name: "^",
                        opcode: FKW_POWER | FT_NUMBER | FU_ANY,
                        produce: function () {
                            return '^';
                        }
                    },
                    {
                        name: "%",
                        opcode: FKW_MODULO_OPERATOR,
                        produce: function () {
                            return 'MODULO_OPERATOR';
                        }
                    },
                    {
                        name: "\u2030",
                        opcode: FKW_PROMILAGE_OPERATOR,
                        produce: function () {
                            return 'PROMILAGE_OPERATOR';                 /* ‰ */
                        }
                    },
                    {
                        name: "\u221a",
                        opcode: FKW_SQRT_OPERATOR | FT_NUMBER | FU_ANY,
                        produce: function () {
                            return 'SQRT_OPERATOR';                     /* √ */
                        }
                    },
                    {
                        name: "\u2248",
                        opcode: FKW_ALMOST_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'ALMOST_EQUAL';                      /* ≈ */
                        }
                    },
                    {
                        name: "\u2260",
                        opcode: FKW_NOT_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'NOT_EQUAL';                         /* ≠ */
                        }
                    },
                    {
                        name: "\u2264",
                        opcode: FKW_LESS_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'LESS_OR_EQUAL';                     /* ≤ */
                        }
                    },
                    {
                        name: "\u2265",
                        opcode: FKW_GREATER_OR_EQUAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'GREATER_OR_EQUAL';                  /* ≥ */
                        }
                    },
                    {
                        name: "\u2212",
                        opcode: FKW_SUBTRACT | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '-';                                 /* − */
                        }
                    },
                    {
                        name: "\u2013",
                        opcode: FKW_SUBTRACT | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '-';                                 /* – */
                        }
                    },
                    {
                        name: "\u2012",
                        opcode: FKW_SUBTRACT | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '-';                                 /* ‒ */
                        }
                    },
                    {
                        name: "\u2014",
                        opcode: FKW_SUBTRACT | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '-';                                 /* — */
                        }
                    },
                    {
                        name: "\u2215",
                        opcode: FKW_DIVIDE | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '/';                                 /* ∕ */
                        }
                    },
                    {
                        name: "\u2044",
                        opcode: FKW_DIVIDE | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '/';                                 /* ⁄ */
                        }
                    },
                    {
                        name: "\u2219",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';                                 /* ∙ */
                        }
                    },
                    {
                        name: "\u2022",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';                                 /* • */
                        }
                    },
                    {
                        name: "\u2261",
                        opcode: FKW_IS_IDENTICAL | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'IS_IDENTICAL';                      /* ≡ */
                        }
                    },
                    {
                        name: "\u2310",
                        opcode: FKW_BOOLEAN_NOT_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'BOOLEAN_NOT';                       /* ⌐ */
                        }
                    },
                    {
                        name: "\u00ac",
                        opcode: FKW_BOOLEAN_NOT_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'BOOLEAN_NOT';                       /* ¬ */
                        }
                    },
                    {
                        name: "!",
                        opcode: FKW_BOOLEAN_NOT_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return '!';
                        }
                    },
                    {
                        name: "\u2229",
                        opcode: FKW_BOOLEAN_AND_OPERATOR | FT_BOOLEAN | FU_DERIVED,
                        produce: function () {
                            return 'BOOLEAN_AND_OPERATOR';              /* ∩ */
                        }
                    },
                    {
                        name: "\u00f7",
                        opcode: FKW_DIVIDE | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '/';                                 /* ÷ */
                        }
                    },
                    {
                        name: "\u00d7",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';                                 /* × */
                        }
                    },
                    {
                        name: "\u00b7",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';                                 /* · */
                        }
                    },
                    {
                        name: "\u2219",
                        opcode: FKW_MULTIPLY | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return '*';                                 /* ∙ */
                        }
                    },
                    {
                        name: "\u00b0",
                        opcode: FKW_DEGREES_OPERATOR,
                        produce: function () {
                            return 'DEGREES_OPERATOR';                  /* ° */
                        }
                    },
                    {
                        name: "\u00b2",
                        opcode: FKW_SQUARE_OPERATOR | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return 'SQUARE_OPERATOR';                   /* ² */
                        }
                    },
                    {
                        name: "\u00b3",
                        opcode: FKW_CUBE_OPERATOR | FT_NUMBER | FU_DERIVED,
                        produce: function () {
                            return 'CUBE_OPERATOR';                     /* ³ */
                        }
                    },
                    {
                        /*
                         * This token is an alternative notation which does not require the curly braces around
                         * a 'fragmented range reference', e.g. `{A1, A2, A3, B1}` is equivalent to `A1 ○ A2 ○ A3 ○ B1`
                         * which could also be written as `A1:A3 ○ B1`
                         */
                        name: "\u25cb",
                        opcode: FKW_ARRAY_CONCATENATION_OPERATOR,
                        produce: function () {
                            return 'ARRAY_CONCATENATION_OPERATOR';      /* ○ */
                        }
                    },
                    {
                        /*
                         * This token is an alternative notation which does not require the curly braces around
                         * a 'fragmented range reference', e.g. `{A1, A2, A3, B1}` is equivalent to `A1 ◦ A2 ◦ A3 ◦ B1`
                         * which could also be written as `A1:A3 ◦ B1`
                         */
                        name: "\u25e6",
                        opcode: FKW_ARRAY_CONCATENATION_OPERATOR,
                        produce: function () {
                            return 'ARRAY_CONCATENATION_OPERATOR';      /* ◦ */
                        }
                    },
                    {
                        name: "@",
                        opcode: FKW_DATA_MARKER,
                        produce: function () {
                            return '@';
                        }
                    },
                    {
                        name: ".",
                        opcode: FKW_DOT,
                        produce: function () {
                            // switch lexer modes RIGHT NOW: next up is the `json_filter_expression` rule!
                            assert(this.topState() !== 'JSON_FILTERING');
                            //this.pushState('JSON_FILTERING');   -- Fixed #880

                            return '.';
                        }
                    }
                ];
                var k, d, tlen, ht;

                ht = [{}, {}, {}, {}];
                for (var k = 0, tlen = definition_table.length; k < tlen; k++) {
                    d = definition_table[k];
                    assert(d.name);
                    ht[d.name.length][d.name] = d;
                }

                this.__operator_hash_table = ht;
            }

            var s1 = false, s2 = false, s3 = false;

            s = yytext;
            switch (s.length) {
            case 3:
                s3 = s;
                s = s.substr(0, 2);
                // fall through
            case 2:
                s2 = s;
                s = s.substr(0, 1);
                // fall through
            case 1:
                s1 = s;
                break;
            default:
                assert(0, "should never get here");
                break;
            }

            // reset `s`:
            s = yytext;

            // now find matches in the operator lookup table, largest match first:
            rv = this.__operator_hash_table[3][s3] || this.__operator_hash_table[2][s2] || this.__operator_hash_table[1][s1];
            if (rv) {
                // push the remainder back into the buffer before we continue:
                if (s.length > rv.name.length) {
                    this.unput(s.substr(rv.name.length));
                }

                if (rv.opcode) {
                    yytext = rv.name;
                } else if (rv.lexer_opcode) {
                    yytext = rv.name;
                }
                return rv.produce.call(this, yylloc, yytext);
            }

            /* This may be a single Unicode character representing some constant or currency */
            if (s.length > 1) {
                this.unput(s.substr(1));
            }
            s = s1;

            rv = parser.getSymbol4Currency(s);
            if (rv) {
                yytext = s;
                return 'CURRENCY';
            }

            // no dice, now see if this is a predefined constant
            rv = parser.getSymbol4DefinedConstant(s);
            if (rv) {
                yytext = rv.value;
                switch (rv.attributes & OPCODE_MASK_FOR_FT_VALUE_TYPE) {
                default:
                    return 'CONSTANT';

                case FT_BOOLEAN:
                    if (rv.value)
                        return 'TRUE';
                    else
                        return 'FALSE';

                case FT_STRING:
                    return 'STRING';
                }
            }

            // when we don't have a match at all, we leave it to the other rules to hit something:
            this.reject();
        %}


<INITIAL>"("
        %{
            return '(';
        %}

")"
        %{
            return ')';
        %}

<INITIAL>"{"
        %{
            return '{';
        %}

"}"
        %{
            return '}';
        %}

<INITIAL>"["
        %{
            return '[';
        %}

"]"
        %{
            return ']';
        %}




/*
 * String Handling
 * ---------------
 */


"\u2039"([^\u203a]*)"\u203a"
        %{                                                  /* ‹string› */
            s = this.matches[1];
            yytext = s;
            return 'STRING';
        %}

"\u201c"([^\u201d]*)"\u201d"
        %{                                                  /* “string” */
            s = this.matches[1];
            yytext = s;
            return 'STRING';
        %}

"\u00ab"([^\u00bb]*)"\u00bb"
        %{                                                  /* «string» */
            s = this.matches[1];
            yytext = s;
            return 'STRING';
        %}


/*
 * Any input which starts with a string marker is assumed to be a string entirely.
 * Hence these two full-line regexes must come before the 'detect string anywhere in the input'
 * regexes which come after these. Those latter regexes will help us parse statements like
 *
 *       '=CONCATENATE("THE YEAR", " ", "2013")'
 *
 *
 * Regex notes
 * -----------
 *
 *       (.*?)
 *
 *  is written like that, i.e. as a NON-greedy regex atom, to ensure that the
 *  optional `'?` / `"?` following it is actually filled when the string terminates
 *  with such a quote. Would the `.*` expression have been greedy, then the regex
 *  engine would legally ignore the following `'?` / `"?` completely as those quotes
 *  would have matched the previous `.*` already, while still producing a legal
 *  match for the quoted string, e.g. `'hello world'` would then produce a
 *
 *       \1 == "hello world'"            (note the trailing quote)
 *
 *  while we want the regex to 'strip' the outer quotes, if there are any.
 */

"'"(.*)$
        %{
            // This lexer rule should only accept Excel string values, i.e. non-formula entities
            // which start with a quote.
            //
            // TODO: later on make the lexer smarter (and a bit faster) by using lexer states
            // instead of this hack which checks the location info to recognize whether this is
            // the very first token we encounter: only when it is does this special situation apply.
            var pos = this.offset - yyleng;
            if (pos > 0) {
                this.reject();
            } else {
                s = this.matches[1];
                // s2 = parser.dedupQuotedString(s, "'");  -- Excel does not 'deduplicate' quotes in literal string values like these.

                yytext = s;
                // In MS Excel you can force any (entire!) formula or other input to be parsed as a string by prefixing it with a single "'" single quote.
                return 'EXCEL_FORCED_STRING';
            }
        %}

'"'(.*)$
        %{
            // This lexer rule should only accept Excel string values, i.e. non-formula entities
            // which start with a quote.
            //
            // TODO: later on make the lexer smarter (and a bit faster) by using lexer states
            // instead of this hack which checks the location info to recognize whether this is
            // the very first token we encounter: only when it is does this special situation apply.
            var pos = this.offset - yyleng;
            if (pos > 0) {
                this.reject();
            } else {
                s = this.matches[1];
                // s2 = parser.dedupQuotedString(s, '"');  -- Excel does not 'deduplicate' quotes in literal string values like these.

                yytext = s;
                // In MS Excel you can force any (entire!) formula or other input to be parsed as a string by prefixing it with a single "'" single quote.
                return 'EXCEL_FORCED_STRING';
            }
        %}

"'"([^']*(?:"''"[^']*)*)"'"{TOKEN_SENTINEL}
        %{
            this.unput(this.matches[2]);

            s = this.matches[1];
            s2 = parser.dedupQuotedString(s, "'");
            yytext = s2;
            return 'STRING';
        %}

'"'([^"]*(?:'""'[^"]*)*)'"'{TOKEN_SENTINEL}
        %{
            this.unput(this.matches[2]);

            s = this.matches[1];
            s2 = parser.dedupQuotedString(s, '"');
            yytext = s2;
            return 'STRING';
        %}





/*
 * Comment parsing
 * ---------------
 */


<INLINE_COMMENT>[^\/\*\)\}#!\u203c\u258c\u2590]+
        %{                                                  /* * / ) | # ! ‼ ▌ ▐ */
            /* keep it all; we haven't hit an end-of-comment marker starting character yet! */
            this.more();
        %}

<INLINE_COMMENT>.
        %{
            for (rv = 0, len = this.inline_comment_end_markers.length; rv < len; rv++) {
                s2 = this.inline_comment_end_markers[rv];
                if (s2[0] === this.matches[0]) {
                    // we got a POTENTIAL MATCH; let's see if we need more:
                    if (s2.length > 1) {
                        // when yes, test the next rule!
                        this.reject();
                        return false;
                    } else {
                        /*
                        * Full match! end of comment reached.
                        *
                        * Remove this last bit from the parsed text and strip leading / trailing whitespace.
                        *
                        * > ### Notes
                        * >
                        * > Since returning actual tokens for any inline comments would
                        * > break the LALR(1) grammar most severely, we concatenate
                        * > comments and attach them to the next token.
                        * >
                        * > Since the 'next token' MAY be `EOF`, we need the parser
                        * > to check if there's any leech called `comment` hanging
                        * > off that EOF it might've got dropped in the in-box...
                        */
                        parser.pushComment();
                        this.popState();
                        return false;
                    }
                }
            }
            // collect input until we hit something we know:
            this.more();
        %}

<INLINE_COMMENT>..
        %{
            /*
             * We only hit this rule when the previous one was `reject()`-ed
             * as that rule will match anything that's the start of this one.
             *
             * Hence we know we have a partial match on a comment terminator,
             * but we need to make sure.
             *
             * We also know that our longest 'end markers' are 2 characters wide,
             * so this solution is sufficient and complete.
             *
             * Now all we have to do is scan the longer-than-1-character
             * comment markers against what we've got here and if there's
             * NO MATCH, we need to keep in mind that nasty people can write
             * comments like `{***}` and we have a hit on `**}` so we may only
             * consume one character here in that case.
             */
            for (rv = 0, len = this.inline_comment_end_markers.length; rv < len; rv++) {
                s2 = this.inline_comment_end_markers[rv];
                if (s2 === this.matches[0]) {
                    /*
                     * Full match! end of comment reached.
                     *
                     * Remove this last bit from the parsed text and strip leading/trailing whitespace.
                     *
                     * Since returning actual tokens for any inline comments would
                     * break the LALR(1) grammar most severely, we concatenate
                     * comments and attach them to the next token.
                     *
                     * Since the 'next token' MAY be `EOF`, we need the parser
                     * to check if there's any leech called `comment` hanging
                     * of that EOF it might've got dropped in the in-box...
                     */
                    parser.pushComment();
                    this.popState();
                    return false;
                }
            }
            // we may only consume a single character, so we `unput()` the last one:
            this.less(1);

            // collect input until we hit something we know:
            this.more();
        %}

<INLINE_COMMENT><<EOF>>
        %{
            parser.pushComment();

            rv = yy.parser.parseError("Unterminated inline comment.", {
                text: yytext,
                //token: $error,
                line: yylloc,
                loc: yylloc,
                outer_loc: yylloc,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            return 'error';
        %}








/*
 * The sag wagon, which mops up the dregs
 * --------------------------------------
 */


\s+
        /*: skip whitespace */


<<EOF>>
        %{
            return 'EOF';
        %}

// When we get to this point in the lexer regex list, we don't know what to do
// with the first character at all (regex: `.`).
//
// In actual practice we find that we need to add a bit of 'sanity/recovery quality'
// to the lexer & grammar because we now would parse **erroneous input** like `Cost1[2014]`
// where `Cost1` is a row label but `2014` is **not** a legal column label, hence the entire
// thing **not** validating as a correct cell reference(!) this time around, as
//
// - ERROR token `C`
// - ERROR token `o` (we don't know what to make of `ost1[2014]` after all!)
// - ERROR token `s` (ditto for `st1[2014]`)
// - lexer & grammar have 'recovered' as now the lexer *can* make something of `t1` in `t1[2014]`:
//   that little snippet happens to validate as a legal cellref `T1`: totally obvious to the lexer,
//   but the resulting color coding in the formula editor is completely unintelligible by humans
//   as we now flag `Cos` as red=ERROR, while `T1` is capitalized and color-coded as a cellref,
//   followed by a `[` open bracket and `2014` numeric value plus a `]` close bracket.
//   --> `T1` (cellref), ...
//
// We don't want to see the above 'error recovery' in our color coding (which is driven by our
// token stream resulting from the lexer activity) so we need to smarten up our lexer just a little
// to improve our tokenization *after* hitting an error. (This is intelligence we add to the lexer
// which is not used by the grammar rules as those just barf after the initial parse error which
// kicked in at `C`(ERROR) already.)
//
// The heuristic we use here is to scan forward (and consume characters) until we hit our first
// TOKEN_SENTINEL. That way we can be sure to skip any half or whole cell/row/column label names
// and have a decent chance at spitting out some more or less decent tokens following
// the error event.
//
// Edit: we don't terminate the error token at the TOKEN_SENTINEL boundary because that one will
// force us to eat the `[` as well, which is not our intent here. We wish to consume entire labels,
// hence a more direct regex is more suitable: when the error character itself is part of a WORD
// we eat the entire label/function name hence we consume the entire DOTTED_WORDS sequence;
// otherwise we know we're looking at an error character which itself is NOT a label and then
// we simply eat that character only. Consequently we now have *two* error catching lexer rules
// below:
{DOTTED_WORDS}
        %{
            rv = yy.parser.parseError("Don't know what to do with this: it's unsupported input.", {
                text: yytext,
                //token: $error,
                line: yylloc,
                loc: yylloc,
                outer_loc: yylloc,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            return 'error';
        %}


// See note for the error lexer rule above: this is where we catch any erroneous non-label character.
.
        %{
            rv = yy.parser.parseError("Don't know what to do with this: it's unsupported input.", {
                text: yytext,
                //token: $error,
                line: yylloc,
                loc: yylloc,
                outer_loc: yylloc,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            return 'error';
        %}










/lex






%token NUMBER INTEGER_NUMBER
%token STRING
%token EXCEL_FORCED_STRING
%token TRUE FALSE

%token CONSTANT
/*
 * predefined functions and User Defined Functions all produce the `FUNCTION` lexer token:
 * parameter list validation is performed in the static analysis phase during parsing.
 */
%token FUNCTION

%token CELLREF
%token COLUMN_ID ROW_ID

%token CELLREF_PARSE_MODE RANGEREF_PARSE_MODE VALUE_PARSE_MODE
%token URI PATH




/*
 * ----------------------------------------------------
 * operator associations and precedence 
 * ----------------------------------------------------
 */



/*
 * To ensure that JISON creates an index number for this token, we must use it at least
 * in one spot in the grammar; JISON ignores `%token` declarations and instead extracts
 * the actual token set from the grammar itself: if a token does not appear in there
 * it is assumed to not exist.
 *
 * Generally speaking, the 'TOPS20' feature would be supported by detecting the token
 * triggering an error condition in the grammar; adding additional productions just to
 * catch the TOPS20 token is useless and space-consuming for the generated grammar.
 *
 * Hence we only use this token in one or two places in the grammar where an `error`
 * clause is not permitted under LALR(1) rules.
 *
 *
 * Geek Aside: Another way to 'register' the token with JISON would be to list it in a
 * bogus rule (i.e. a production that is never reached); using `%nonassoc` or '%left' does
 * not help in 'registration': the only way is via appearance in the grammar rules...
 */
%left '?'

%nonassoc CURRENCY

%nonassoc '$' ':' '[' ']' '{' '}' '(' ')'

%nonassoc '@'
%nonassoc '.'

%nonassoc PROMILAGE_OPERATOR DEGREES_OPERATOR
%nonassoc PERCENTAGE_OPERATOR

%left ARRAY_CONCATENATION_OPERATOR
%left ','

%left STRING_CONCATENATION_OPERATOR
%left BOOLEAN_AND_OPERATOR BOOLEAN_OR_OPERATOR
%nonassoc BOOLEAN_NOT
%nonassoc '!'
%nonassoc '>' '<' GREATER_OR_EQUAL LESS_OR_EQUAL ALMOST_EQUAL
%left '=' IS_EQUAL NOT_EQUAL IS_IDENTICAL NOT_IDENTICAL
%left '+' '-'
%left '*' '/'
%right MODULO_OPERATOR
%right '^'
%right SQUARE_OPERATOR CUBE_OPERATOR
%right SQRT_OPERATOR

%nonassoc UNARY_OPERATOR_PRECEDENCE









%start start_parsing



/*
 * %parse-param adds one or more named arguments to the action call; these user args are assumed to be passed to Parser.parse(input, ...args...)
 */
%parse-param cfg one two


%{
    /*
     * This chunk is included in the parser code, before the lexer definition section and after the parser has been defined.
     *
     * WARNING:
     *
     * Meanwhile, keep in mind that all the parser actions, which will execute inside the `parser.performAction()` function,
     * will have a `this` pointing to `$$`.
     *
     * If you want to access the lexer and/or parser, these are accessible inside the parser rule action code via
     * the `yy.lexer` and `yy.parser` dereferences respectively.
     */

    //console.log("parser object definition: ", this);
%}


%% /* language grammar */


%{
    /*
     * This chunk is included at the top of the actionHandler itself.
     */
    var rv, range;

    //console.log("parser exec rule: ", yystate, this, yy.lexer.options, arguments);

    var patch_tokenstream = yy.lexer.options.patch_tokenstream;
    assert(patch_tokenstream);
    var patch_resulttype = yy.lexer.options.patch_resulttype;
    assert(patch_resulttype);
%}


start_parsing
    : do_the_work EOF
        {
            // Note: we MAY return values such as 'undefined' or 'null', which would otherwise be picked up
            // by the JISON parser rig itself and be converted to a *boolean* `TRUE` value (action code 3 inside
            // the jison LALR parser stack engine).
            //
            // To thwart this 'default return value' behaviour of JISON we always wrap the actual calculated
            // value in an object, where our wrapper code will then extract it once we get outside the jison
            // engine/driver.
            return {
                value: $do_the_work
            };
        }

    | do_the_work error
        {
            rv = yy.parser.parseError("We do not expect anything following the valid expression.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            return {
                value: NaN
            };
        }
    ;


do_the_work
    : '=' math_expression
        {
            patch_resulttype(FT_FORMULA);
            $$ = $math_expression;

            // check this block in combination with outerErrorCheck in __support_functions.js
            if ($$ instanceof ErrorSignal) {
                // do not change anything: $$ stays ErrorSignal
            } else if ($$.__collection) {
                // if this is a range
                $$ = Visyond.Functions.ERROR.na;
            } else if(typeof $$ === 'string' || typeof $$ ==='boolean') {
                // do not change anything
            } else if ($$ instanceof CellRefRepresentation) {
                $$ = $$.valueOf();
            } else {
                if (isNaN($$) || !isFinite($$)) $$ = Visyond.Functions.ERROR.na;
            }
        }
//
//    | '=' error
//        {
//            rv = yy.parser.parseError("Expected a formula.", {
//                text: $error,
//                token: $error,
//                line: @error,
//                loc: @error,
//                outer_loc: @$,
//                expected: [],
//                recoverable: false
//            });
//            assert(rv === null);
//            $$ = NaN;
//        }

    | accept_direct_value
        {
            rv = $accept_direct_value;
            // A bit of a hack: when you enter a 'direct value EXPRESSION', e.g. `E1`, where the
            // referenced cell doesn't exist and therefor has no value (`undefined`), we *still*
            // want the resulting value right here to be one of string/boolean/number/date/whatever,
            // but we certainly DO NOT want it to produce the value `undefined`.
            //
            // Hence we coerce the result (as little as possible) before feeding it back to the caller.
            $$ = coerceValueToStringIfUndefined(rv);
        }

    | CELLREF_PARSE_MODE cell_reference
        {
            $$ = $cell_reference;
        }

    | CELLREF_PARSE_MODE error
        {
            rv = yy.parser.parseError("Expected a single cell reference.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }

    | RANGEREF_PARSE_MODE any_range_reference
        {
            /*
             * Check whether the AST is really a RANGEREF and not a CELLREF as the `any_range_reference` rule
             * can deliver a single CELLREF node due to LALR(1) grammar restrictions keeping us from
             * completely separating CELLREF and RANGEREF parsing.
             *
             * Anything apart from a RANGEREF should trigger an error report.
             */
            if (Array.isArray($any_range_reference)) {
                $$ = $any_range_reference;
            } else {
                rv = yy.parser.parseError("Expected a cell range reference.", {
                    text: $any_range_reference,
                    token: $any_range_reference,
                    line: @any_range_reference,
                    loc: @any_range_reference,
                    outer_loc: @$,
                    expected: [],
                    recoverable: false
                });
                assert(rv === null);
                $$ = NaN;
            }
        }

    | RANGEREF_PARSE_MODE error
        {
            rv = yy.parser.parseError("Expected a cell range reference.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }

    | VALUE_PARSE_MODE accept_direct_value
        {
            /*
             * TODO:
             *
             * Check whether the AST so far is 'basic' and suitable for 'folding' to a single value.
             *
             * Anything else should trigger an error report.
             */
            $$ = $accept_direct_value;
        }
//
//    | VALUE_PARSE_MODE error
//        {
//            rv = yy.parser.parseError("Expected a value or value expression.", {
//                text: $error,
//                token: $error,
//                line: @error,
//                loc: @error,
//                outer_loc: @$,
//                expected: [],
//                recoverable: false
//            });
//            assert(rv === null);
//            $$ = NaN;
//        }
    ;


accept_direct_value
    : value

    | constant

    | percentage

    | price

    | radians

    | boolean

    | string

    | percentage_alternative_for_data_entry
        {
            /* see the rule comment: this is to support Excel-compatible value data entry */
            $$ = $percentage_alternative_for_data_entry;
        }

    | EXCEL_FORCED_STRING
        {
            patch_resulttype(FT_STRING);

            /* see the rule comment: this is to support Excel-compatible value data entry */
            assert(typeof $EXCEL_FORCED_STRING === "string");
            $$ = $EXCEL_FORCED_STRING;
        }

    | error
        {
            rv = yy.parser.parseError("Expected a value or formula expression.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;





/*
 * Math, operator precedence and associativity
 * -------------------------------------------
 *
 * Note that the operator precedence is largely taken care of by the order in which these
 * 'expression' rules are listed, or more precisely: the order in which these rules refer
 * to one another! (This happens to be the order of appearance in this file as that simplifies
 * maintenance / readability, but that is not necessary.
 *
 * The operator associativity is partly manged by the `%left` and `%right` token definitions
 * further above, which are employed by JISON when the rules below are ambiguous regarding
 * associativity. For the most part, the rules themselves already fix the operator associativity
 * (by using left-recursive or right-recursive definitions).
 */


math_expression
    : boolean_expression
    ;


/*
 * Of course a boolean expression can also be just a numeric expression (e.g. `=2+3`), it just means
 * boolean expressions have the LOWEST PRECEDENCE in the math expressions accepted by the formula parser.
 *
 * > ### Notes
 * >
 * > This rule-based BNR notation is the preferred way to 'annotate' operator precedence in a grammar.
 * >
 * > `%left` / `%right` are special attributes to resolve _shift/reduce conflicts_ for situations like
 * > in `=1+2+3`: do we produce `1+2` first (`%left`) or `2+3` first (`%right`) and then the other `+`?
 */
boolean_expression
    : boolean_expression[first] BOOLEAN_AND_OPERATOR boolean_expression[last]
        {
            // Excel: `=AND("T",1)` gives `#VALUE!`; we do not emulate that behaviour here!
            $$ = !!($first && $last);
        }

    | boolean_expression[first] BOOLEAN_OR_OPERATOR boolean_expression[last]
        {
            // Excel: `=OR("T",1)` gives `#VALUE!`; we do not emulate that behaviour here!
            $$ = !!($first || $last);
        }

    | compare_expression
    ;


compare_expression
    : compare_expression[first] NOT_EQUAL compare_expression[last]
        {
            // WARNING: see the Excel note below at IS_EQUAL: we don't really have a type-agnostic compare available!
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ($first !== $last);
        }

    | compare_expression[first] NOT_IDENTICAL compare_expression[last]
        {
            // WARNING: see the Excel note below at IS_EQUAL: we don't really have a type-agnostic compare available!
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ($first !== $last);
        }

    | numeric_expression[first] ALMOST_EQUAL numeric_expression[last]
        {
            var f = coerceValueToNumeric($first);
            var l = coerceValueToNumeric($last);
            if (!isNaN(f) && !isNaN(l)) {
            	// TODO: constant values: move this outside so we don't need to calculate this every time!
            	var ε = 1e-9;
            	var ACCEPTED_NUMERIC_ACCURACY_LOG = Math.log(1 + ε);

            	// NEARNESS is a *relative* thing: it's about accuracy. Here we hardcode an 'accepted accuracy' of 0.001ppm.
            	// Since we use logarithms for this, we must ensure that both values being compared are non-zero *positive*
            	// numbers, hence we offset them by the minimum of the two, plus 1.0:
            	var lowest = Math.min(f, l);
            	f += 1 + lowest;
            	l += 1 + lowest;
	            if (isFinite(f) && isFinite(l)) {
	            	var df = Math.log(f);
	            	var dl = Math.log(l);
		            assert(isFinite(f));
		            assert(isFinite(l));
	                $$ = (Math.abs(df - dl) <= ACCEPTED_NUMERIC_ACCURACY_LOG); /* ε */
	            } else {
	                // arguments may be nearly-out-of-range numeric values: in this case we cop out and turn this into
	                // an identity check; if only one of them 'INF-ed out', we got a winner too.
                    $$ = ($first === $last);
	            }
            } else {
                // arguments may be a non-numeric type: here we perform a type-agnostic comparison then.
                // Also make sure that NaN compares to NaN as TRUE (JavaScript gives FALSE for that particular comparison)
                $$ = ($first == $last) || (isNaN($first) && isNaN($last));
            }
        }

    | compare_expression[first] IS_IDENTICAL compare_expression[last]
        {
            // WARNING: see the Excel note below at IS_EQUAL: we don't really have a type-agnostic compare available!
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ($first === $last);
        }

    | string_concatenation_expression[first] GREATER_OR_EQUAL string_concatenation_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first >= $last);
        }

    | string_concatenation_expression[first] LESS_OR_EQUAL string_concatenation_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first <= $last);
        }

    | string_concatenation_expression[first] '>'[greater_than] string_concatenation_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first > $last);
        }

    | string_concatenation_expression[first] '<'[less_than] string_concatenation_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first < $last);
        }

    | compare_expression[first] '='[equals] compare_expression[last]
        {
            // Excel says `="1"=1` is FALSE so doesn't perform auto-type-coercion while JavaScript does.
            // Hence we have to use `===` instead of `==` here:
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ($first === $last);
        }

    | compare_expression[first] IS_EQUAL compare_expression[last]
        {
            /*
             * This is just another notation for `=`, but we don't allow `==`, etc. as start markers
             * of a formula, so we end up having to 'is equal' opcode tokens, alas.
             */
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ($first === $last);
        }

    | string_concatenation_expression
    ;


/*
 * The very LOWEST precedence in a (non-boolean) expression is reserved for STRING CONCATENATION (`&`).
 */
string_concatenation_expression
    : string_concatenation_expression[first] STRING_CONCATENATION_OPERATOR string_concatenation_expression[last]
        {
            $first = coerceValueToStringIfUndefined($first);
            $last = coerceValueToStringIfUndefined($last);
            $$ = ('' + $first + $last);
        }

    | numeric_expression
    ;


/*
 * The LOWEST precedence in any numeric expression is reserved for `ADD` (`+`) and `SUBTRACT` (`-`).
 */
numeric_expression
    : numeric_expression[first] '+'[add] numeric_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first + $last);
        }

    | numeric_expression[first] '-'[subtract] numeric_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=FALSE>1.0e300` gives TRUE: we do not emulate that behaviour here.
            //
            // Excel treats TRUE and FALSE as being *outside* the numeric range.
            // Other Excel peculiarities, such as `=TRUE+1` --> `` (empty!) are also unsupported!
            $$ = ($first - $last);
        }

    | multiply_expression
    ;


/*
 * Next in precedence are `MULTIPLY` and `DIVIDE`.
 */
multiply_expression
    : multiply_expression[first] '*'[multiply] multiply_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            // Excel: `=TRUE*1` --> `1`: for multiplication, TRUE and FALSE are treated as numeric 1 and 0, respectively.
            // Of course, we *do* support that behaviour!
            $$ = ($first * $last);
        }

    | multiply_expression[first] '/'[divide] multiply_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            $$ = ($first / $last);
            // TODO: detect division by zero for two non-error inputs and then report #DIV/0
        }

    | multiply_expression[first] MODULO_OPERATOR multiply_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            $$ = ($first % $last);
        }

    | exponential_expression
    ;


/*
 * Next in precedence is the `POWER` operation: `1*2**4 = 16`.
 *
 * > ### Note
 * >
 * > The *SQUARE ROOT* is just another exponential operator and hence ends up in here,
 * > while we give it a `%right` associativity because we want this notation to resolve
 * > to the given value (rather than an error / imaginary value):
 * >
 * >     = SQRT 2**4 = SQRT(2**4) = 4
 * >
 * > while `^` also exhibits `%right` associativity as
 * >
 * >     = 2**3**2 ~ 2**(3**2) = 512
 */
exponential_expression
    : atomic_expression[first] '^'[power] exponential_expression[last]
        {
            $first = coerceValueToNumeric($first);
            $last = coerceValueToNumeric($last);
            $$ = Math.pow($first, $last);
        }

    | SQRT_OPERATOR exponential_expression
        {
            $exponential_expression = coerceValueToNumeric($exponential_expression);
            $$ = Math.sqrt($exponential_expression);
        }

    | exponential_expression SQUARE_OPERATOR
        {
            $exponential_expression = coerceValueToNumeric($exponential_expression);
            $$ = Math.pow($exponential_expression, 2);
        }

    | exponential_expression CUBE_OPERATOR
        {
            $exponential_expression = coerceValueToNumeric($exponential_expression);
            $$ = Math.pow($exponential_expression, 3);
        }

    | exponential_expression '?'[TOPS20_help_request]
        {
            rv = yy.parser.parseError("TODO: provide inline/online help for this expression.", {
                text: $TOPS20_help_request,
                token: $TOPS20_help_request,
                line: @TOPS20_help_request,
                loc: @TOPS20_help_request,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }

    | atomic_expression
    ;


/*
 * The rule which accepts the highest precedence operators, i.e. unary operators.
 *
 * Anything in here either has to have braces surrounding an expression or can only be single value (or cell reference, etc.).
 */
atomic_expression

    /*
     * These next two refer to a `data_source` as we need to construct an unambiguous LALR(1) grammar
     * and simply using `e` in the two rules below would create an ambiguity between these and the `+` / `-` 'number'
     * and  `+` / `-` 'constant' rules: either would be able to parse `+5` / `-PI` and that is an ambiguity.
     *
     * By using `data_source` we achieve two things at the same time:
     *
     *  - we allow things like `+ABS(A1)` that way, next to `-5`
     *  - we now also have a rule set which doesn't need the `%prec` tweak to disambiguate.
     *
     * Incidentally, the new grammar effectively forbids 'ludicrous' constructs like
     *
     *      +TRUE, -FALSE, ++5, ---SUM(A1:A5)
     *
     * See also issue #177 (https://github.com/GerHobbelt/visyond/issues/177).
     */

    : unary_expression

    | data_source

    | value

    | constant

    | percentage

    | price

    | radians

    | boolean

    | string

    | error
        {
            rv = yy.parser.parseError("Expected a value or formula expression.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;


unary_expression
    : '-'[minus] unary_expression_rvalue
        {
            $$ = -coerceValueToNumeric($unary_expression_rvalue);
        }

    | '+'[plus] unary_expression_rvalue
        {
            $$ = +coerceValueToNumeric($unary_expression_rvalue);
        }

    | '!'[negate] unary_expression_rvalue
        {
            if (!isNaN($unary_expression_rvalue)) {
                $$ = !($unary_expression_rvalue);   // No need to coerce the operand to numeric value before we apply boolean NOT
            } else {
                // propagate errors (NaN)
                $$ = $unary_expression_rvalue;
            }
        }

    | BOOLEAN_NOT unary_expression_rvalue
        {
            if (!isNaN($unary_expression_rvalue)) {
                $$ = !($unary_expression_rvalue);   // No need to coerce the operand to numeric value before we apply boolean NOT
            } else {
                // propagate errors (NaN)
                $$ = $unary_expression_rvalue;
            }
        }
    ;


unary_expression_rvalue
    : data_source

    | error
        {
            rv = yy.parser.parseError("Expected a numeric value or bracketed formula expression.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;








/*
 * Data sources / filters and grid cell storage
 * --------------------------------------------
 *
 * The formula parser supports special 'JSON database/filtering' subexpressions:
 * these are special constructs which allow us to load data from
 * external sources and program the (more or less hierarchical) data filters in a single cell in the grid: the
 * idea there is that a grid cell is not merely able to carry a single value (or formula), but can carry a
 * series of values (i.e. a 'database table') and have the formulas referencing that cell operate on those values:
 * that way you can process bulk data in a spreadsheet-like grid without having to use huge numbers of grid cells
 * to 'distribute / place' all the input data values.
 *
 *
 * The grammar definition of these 'data source / filter' subexpressions
 * ---------------------------------------------------------------------
 *
 * Data sources (and extracting information elements from them) is done using special functions:
 *
 *  - **`DATA_SOURCE("<url>")`**
 *       is your basic data server (which spits out a JSON structure, which always
 *       starts with the 'data' root)
 *
 *  - **`DATA_FILTER(data_source, json_filter_expression)`**
 *       is your fundamental filter operator which extracts a basic value or new JSON structure
 *       from the given source.
 *
 * Note that the json_filter_expression has a `.` dot-separator to enter JSON tree levels and
 * uses the `[n]` array/object index operation to access a particular entry in a JSON data array/object.
 * This mixes nicely with regular formula expressions, except the `[n]` operation there as that collides
 * with the way cell_references may be written (`column[row]`), so we are in violation of LALR(1) and
 * need the 'lexer hack' to help us out of this conundrum.
 *
 * Furthermore you may observe that the names used in the JSON filter expression will be (arbitrary,
 * i.e. we don't know them up front!) names in the JSON data tree, rather than column, row or other
 * 'regular' formula symbol names, so here we have another lexer conundrum: again, it's the 'lexer hack'
 * to the rescue: by switching lexer states we can make the lexer TEMPORARILY forget about those
 * pesky formula names (functions, column & row labels, etc.) and treat these names as
 * 'something in your JSON, okay, fine'.
 *
 *
 * Then what is this 'lexer hack' exactly?
 * ---------------------------------------
 *
 * We know this one from the good ol' days of lex/yacc and it goes like this:
 *
 * - we assume you're a *EXPERT* grammar designer (anything less and you gotta shoo shoo or
 *   the craziest parsing bugs will be yours to deal with!)
 *
 * - so you know how an LALR(1) grammar like this operates and more specifically: you know
 *   EXACTLY when the parser will take you up on that '*(1)' look-ahead.
 *
 * - hence you may inject a timely call to the lexer to switch parsing modes, which here
 *   means you know the right spot, 100% guaranteed, where you can and MUST call `lexer.begin(CONDITION)`.
 *
 * - this, in turn, will switch the lexer to observing the coming input through different
 *   eyes by following a whole different set of lexing rules from this point onward.
 *
 * - thus having 'hacked the lexer', you're about half-way done, or rather, a third-way done:
 *
 *   + 2/3rd:
 *     you also must be 100% certain about the spot (mindful of that LA(k) again...) where
 *     switch the lexer BACK to the regular parsing mode ('start condition' in flex parlance).
 *
 *   + 3/3rd:
 *     and here's the icepick in the forehead (cf. Zappa): now you have to go and make
 *     sure your grammar rules AND ACTIONS are a perfect fit for your actual parser GENERATOR:
 *     some tools support mid-rule actions (LALR tools are notorious for 'consuming
 *     the look ahead token' when you do that, or in other words: your tool MAY treat that
 *     mid-rule action block as 'one token' thus relieving you of any chance to get
 *     anything useful out of that generator of yours when you need that precious 1-piece
 *     look-ahead to look 'beyond' that action chunk.
 *
 *     Other generator tools simply don't allow mid-rule actions and there you are,
 *     conjuring up grammar rules to make the intended action happen, at the cost of
 *     rule comprehensibility to innocent bystanders.
 *
 *     I picked the latter tactic as that's the most 'portable': the toughest part is
 *     getting them rules correct and this way, that has been accomplished henceforth.
 *
 *
 * The hack goes like this:
 *
 * - we know we are going to need lexer state switching inside that `DATA_FILTER(data_source, json_filter_expression)`
 *   expression right after the first `,` comma right there, so this MAY LOOK LIKE REGULAR FUNCTION EXPRESSION BUT ISN'T:
 *   hence we start the party by creating a separate rule to handle this `DATA_FILTER` 'function expression'
 *   so as to keep the mess in a closely restricted area (`DATA_FILTER` definitely isn't going to be one of those
 *   `FUNCTION` tokens you'll see so often for all them other regular functions, e.g. `POWER(n, e)`).
 *
 * - then we go and sit down to do the complex bit of chopping the rule into bits that end
 *   with the lexer state change in their action, thanks to look-ahead analysis:
 *
 *   - we take the sensible grammar rule
 *
 *          data_filter : DATA_FILTER '(' data_source ',' json_filter_expression ')'
 *
 *     and break it up into parts, each of which do not require any LA(1) to decide to reduce:
 *
 *   - the first 'break' we need is at that comma: once we get that one, we don't need any look-ahead to
 *     'reduce' the rule we want, so we come up with `data_filter_before_json_filter_expression`.
 *     Remember we need to switch lexer states RIGHT NOW because the next to enter the parser stream
 *     is that `json_filter_expression` which will contain names which will not exist in our
 *     symbol table and when they are, those symbols will have it completely and utterly WRONG.
 *
 *   - next we like that final `)` which signals the end of the `DATA_FILTER` 'function call' and
 *     we WANT the reduce to happen there with zero look-ahead, which will happen as we _reduce_
 *     the datafilter rule once we hit that closing ')' - only after the _reduce_ do we need
 *     another token to continue parsing the remainder of the encompassing formula expression.
 *
 *     Remember I announced this 'bouncing back to normal' in the '2/3rd' part above!
 *
 *   - so far, so good. Now we need something to TEMPORARILY flip the lexer to 'normal formula mode'
 *     when the filter expression either contains a sector function or array index, i.e. we need
 *     to flip at `(` / `[` and back again to JSON mode when we hit the matching `]` / `)`.
 *     By now, you should've got the hang of it and understand why those long-named rules show
 *     up below, just so we can catch a proper `e` expression in there to allow maximum filter
 *     flexibility... (Don't you want the grid to calculate indexes to fetch? I do!)
 */

data_source
    : multivalued_data_source

    /*
     * This is wicked bit of grammar as the _lexer_ pushes the lexer state to become 'JSON_FILTERING' when
     * the _lexer_ hits the '.' dot in this rule, while the _lexer_ is aware which characters terminate
     * said mode, switching back to the default 'INITIAL' lexer mode by popping the 'JSON_FILTERING' state
     * when it runs into a character which is 'illegal' in the 'JSON_FILTERING' state but (possibly)
     * legal in the 'INITIAL' state...
     */

    | multivalued_data_source '.'[dot] json_filter_expression
        {
            rv = yy.parser.parseError("Dotted references into cell values are currently not support yet.", {
                text: $json_filter_expression,
                token: $json_filter_expression,
                line: @json_filter_expression,
                loc: @json_filter_expression,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;


multivalued_data_source
    : FUNCTION '('[open] arglist ')'[close]
        {
            /*
             * get the function name and attributes from the token argument:
             */
            var f_tok_locinfo = @FUNCTION;
            var f_tok_spec = $FUNCTION;
            var a = $arglist;
            var chk;

            var precedentsFromFunction;

            //console.log("exec function: ", f_tok_locinfo, f_tok_spec, a);
            assert(vUserPreferences.quality >= VQ_PRODUCTION_READY ? f_tok_spec.opcode ? (f_tok_spec.opcode.implementation || f_tok_spec.opcode.value !== undefined) : false /* only entries with good implementation are allowed */ : true);

            if (f_tok_spec.opcode && f_tok_spec.opcode.implementation) {
                // TODO: call generic validation function which picks up .opcode.parameters_set_definition[]
                // WARNING: that def array is not the bees' knees as it is flaky concerning functions
                // which accept arbitrary number and/or type of arguments: e.g. SUM, MAX, MIN: it TRIES to
                // encode that knowledge in the array, but you WILL hit snags as the idea has been coded but
                // never tested as is: THIS is testing time... :-(

                chk = yy.parser.passingArgumentSetValidation(f_tok_spec.opcode, a);
                if (chk) {
                    //console.log("Function " + f_tok_spec.text + ": ", chk);

                    // Implementation Notes
                    // --------------------
                    //
                    // You MUST invoke the custom parseError() coming from parserinput.js@134 by using the 'yy'
                    // variable as that one is the only one pointing at your 'live' Parser instance.
                    // ('this' points to the current yyval without the parser actions, which contrasts with the lexer actions...)
                    if (chk.is_user_failure) {
                        // When the error is a user formula entry mistake, it will abort and flag the formula as an error.
                        rv = yy.parser.parseError("Function " + f_tok_spec.text + ": " + chk.message, {
                            text: $FUNCTION,
                            token: $FUNCTION,
                            line: @FUNCTION,
                            loc: @FUNCTION,
                            expected: [],
                            recoverable: false,
                            failure_info: chk
                        });
                        assert(rv === null);
                        $$ = NaN;
                    } else {
                        // Otherwise, the validation code discover a data input ('sourcing') error, which doesn't invalidate
                        // the function used, it merely will make it *fail* at run-time, producing an error (NaN) value.
                        //
                        // This type of error has no further impact: it only should be reported to help the user while she is
                        // entering the formula, thus serving as a notification that "you shouldn't expect anything sane from this
                        // formula given these inputs you're feeding it!"
                        //
                        // Ergo we DO report this issue, but DO NOT push an ERROR token into the tokenstream or otherwise abort
                        // the formula parsing process right now.
                        vGraph._dispatchEvent(vGraph.EVENT.onParseError, {
                            message: "Function " + f_tok_spec.text + ": " + chk.message,
                            dataErrorInfo: chk
                        });
                        // continue as if nothing untoward happened:
                        chk = false;
                    }
                }

                if (!chk) {
                    //console.log("a: ", a); // this is an array of values: one value per function argument.
                    if (f_tok_spec.opcode.subject_category_references === FCT_CATEGORY_QA) {
                        // provide our QA UDFs with location info for better reporting:
                        a.push({
                            command_token: f_tok_spec,
                            command_locinfo: @FUNCTION,
                            args_start_locinfo: @open,
                            args_locinfo: @arglist,
                            args_end_locinfo: @close
                        });
                    }
                    //WAS: $$ = f_tok_spec.opcode.implementation.apply(this, a);
                    $$ = Visyond.Functions.__exec_wrapper(f_tok_spec, a);        // 'flatten' and 'coerce' the argument list where needed.

                    // console.log("processing function in parser: ", f_tok_spec.opcode);

                    var kk;
                    if(f_tok_spec.opcode.precedents) {
                        precedentsFromFunction = Visyond.Functions.__exec_wrapper(f_tok_spec, a, "precedents");
                        for(kk = 0; kk < precedentsFromFunction.length; kk++) {
                            // we signal that this is a precedent created by function (e.g., OFFSET) manipulation
                            precedentsFromFunction[kk].fromFunction = true;
                            addCellNameToPrecedents(precedentsFromFunction[kk]);
                        }
                    }
                }
            } else if (f_tok_spec.opcode && f_tok_spec.opcode.value != null) {
                // We are invoking an Excel-like 'function constant'.
                // Make sure didn't pass any parameters, as passing any would be illegal.
                //
                // Note that the 'epsilon' argument (of which we expect exactly ONE), itself is
                // encoded as NULL!
                assert(a.length >= 1);
                if (a.length !== 1 && a[0] !== null) {
                    //console.log("Functional CONSTANT " + f_tok_spec.text + ": ", a);
                    // Implementation Notes
                    // --------------------
                    //
                    // You MUST invoke the custom parseError() coming from parserinput.js@134 by using the 'yy'
                    // variable as that one is the only one pointing at your 'live' Parser instance.
                    // ('this' points to the current yyval without the parser actions, which contrasts with the lexer actions...)
                    rv = yy.parser.parseError("Functional CONSTANT " + f_tok_spec.text + ": does not accept any arguments", {
                        text: $FUNCTION,
                        token: $FUNCTION,
                        line: @FUNCTION,
                        loc: @FUNCTION,
                        expected: [],
                        recoverable: false
                    });
                    assert(rv === null);
                    $$ = NaN;
                } else {
                    $$ = f_tok_spec.opcode.value;
                }
            } else {
                // we are trying to invoke a function which does NOT have any implementation!
                // This is an error - of the kind of 'not implemented yet?'
                rv = yy.parser.parseError("Function " + f_tok_spec.text + " has not been implemented yet.", {
                    text: $FUNCTION,
                    token: $FUNCTION,
                    line: @FUNCTION,
                    loc: @FUNCTION,
                    expected: [],
                    recoverable: false
                });
                assert(rv === null);
                $$ = NaN;
            }
        }

    | '(' math_expression ')'
        {
            $$ = $math_expression;
        }

    /* defining ranges only in functions taking arrays, ranges are invalid per se */

    | cell_reference
        {
            $$ = getCellValueByLabel($cell_reference);
        }
    ;












json_filter_expression
    : one_json_filter_level

    | one_json_filter_level[left] '.'[dot] json_filter_expression[right]
        {
            rv = yy.parser.parseError("Dotted references into cell values are currently not support yet.", {
                text: $json_filter_expression,
                token: $json_filter_expression,
                line: @json_filter_expression,
                loc: @json_filter_expression,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;


one_json_filter_level
    : JSON_FIELD_NAME

    | JSON_FILTER_FUNCTION '(' arglist ')'
        {
            $$ = $JSON_FILTER_FUNCTION;
        }

    | one_json_filter_level '[' math_expression ']'[last]
        {
            $$ = $one_json_filter_level;
        }

    /*
     * **DANGER**: the lexer can be either state: 'JSON_FILTERING' or 'INITIAL'.
     * (And be aware that these states may be nested...)
     *
     * This type of crysis ;-) can occur when, for example, processing a json filter function argument
     * which includes some json filter function itself: two levels of 'JSON_FILTERING' and
     * at least one level of 'INITIAL' in between those two and depending on where and when
     * the ERROR fired, a 'INITIAL' level on top.
     */

    | error
        {
            rv = yy.parser.parseError("Sub-level filters into cell values are currently not support yet.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;









/*
 * Cell References and Cell Ranges
 * -------------------------------
 *
 * Cell _ranges_ are invalid outside the use of these as a function parameter, e.g. `SUM(A1:D20)` or when the special
 * `PARSE_MODE_DETECTION` parse mode `RANGEREF_PARSE_MODE` is invoked by the caller invoking the parser.
 *
 * Next to the usual Excel notation we also support a 'fragmented range reference' notation which we had to design
 * in as we want the user to be able to drag & drop any cells in the grid, for instance when the need arises to
 * reorganize a model, also when those cells are part of a range reference such as the aforementioned `SUM(A1:D20)`.
 *
 * Microsoft Excel breaks (in the sense that the model is broken) when you drag / move, say cells B2..B10 to another
 * place outside the range listed in the example formula (which would itself exist outside the given area); we
 * keep the model fully intact by rewriting the formula after the drag / move operation (say we move them to
 * column `F`, starting at `F30`) like this:
 *
 *      SUM(A1:D20)
 *          exec move operation of B2:B10 to F30..  -->
 *      SUM({A1:A20,B1,F30:F39,B11:B20,C1:D20})
 *
 * More power to Cell References
 * -----------------------------
 *
 * As we support row and column labels, cell references can use those labels to improve human legibility of said
 * labels: after all it makes more sense to you reading `Revenues[2012]` than `K39`, wouldn't it?
 *
 * As this parser (or rather: the lexer!) can help disambiguate references when whitespace is involved, there is
 * nothing stopping us from using whitespace in cell references as if we were talking to a human rather than
 * a machine:
 *      Revenues 2012
 * would be a legal cell reference, just as `Revenues[2012]` would be.
 *
 * The lexer has the responsibility to provide us with the properly disambiguated tokens, hence the burden to
 * differentiate between `F 20` (when we want to support recognition of classic currencies such as
 * the French franc (`F`)) as a currency value versus `F 20` as a cell reference is entirely the domain of the
 * lexer.
 *
 * However, that's a bit of a white lie, really, as we do not want the lexer to reproduce a lot of the grammar,
 * hence we have certain grammar rules included here which allow the lexer to be as dumb as possible regarding
 * cell reference disambiguation: references such as
 *
 *      A[20]
 *
 * are encoded by the lexer as a
 *
 *      COLUMN_ID `[` INTEGER_NUMBER `]`
 *
 * token sequence, which we pick up via the rules
 *
 *      cell_reference -> basic_column_id row_id_as_2nd_part
 *
 *      basic_column_id -> COLUMN_ID
 *
 *      row_id_as_2nd_part -> bracketed_row_index
 *
 *      bracketed_row_index -> bracketed_row_index_expression
 *
 *      bracketed_row_index_expression -> '[' math_expression ']'
 *
 *      math_expression -> boolean_expression -> compare_expression
 *          -> string_concatenation_expression -> numeric_expression
 *          -> ... -> atomic_expression -> value -> number -> INTEGER_NUMBER
 *
 * The grammar also allows advanced cell reference constructs which are simply impossible to achieve in Excel
 * without the use of extra functions: using the 'bracket notation' above, nothing stops you from
 * creating a 'dynamic' cell reference, where the actual cell location is determined by a calculation, i.e.
 * another cell's value, like this:
 *
 *      A[20 + Indexes[1]]
 *
 * where `Indexes` is a column label name in this example, thus referencing the cell `Indexes[1]` which will
 * provide a value (which will be coerced to an integer number) which will change the actual cell
 * referenced.
 *
 * Regarding cell reference disambiguation, all we do here is
 * combine the various parts produced by the lexer into a single cell reference. Or when
 * such turns out to be the input, a, possibly 'fragmented', cell _range_ reference.
 */

cell_reference
    : fundamental_cell_reference

    | remote_address fundamental_cell_reference
        {
            rv = yy.parser.parseError("Remote / Cross-project cell references are currently not support yet.", {
                text: $remote_address,
                token: $remote_address,
                line: @remote_address,
                loc: @remote_address,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            $$ = NaN;
        }
    ;


/*
 * To help the LALR(1) grammar stay LALR(1) we must specify the `remote_address_marker` bit in here
 * with `string` (and consequently also the others, but it's the `string` rule which puts the
 * grammar on edge here); the alternative, placing it in the outer rule `cell_reference` like
 * this
 *
 *     | remote_address remote_address_marker fundamental_cell_reference
 *
 * makes jison break out a sweat and report reduce/reduce conflicts:
 *
 *     - reduce by rule: remote_address -> string
 *     - reduce by rule: atomic_expression -> string
 *
 * Tread carefully...
 */
remote_address
    : string remote_address_marker
        {
            // classic Excel mode: the 'remote' bit is stored in a string
            $$ = $string;
        }

    | URI optional_remote_address_marker
        {
            // we accept an OPTIONAL 'remote address marker' as '/' (which is part of the uri path) at the end is good enough as a separator too
            $$ = $URI;
        }

    | PATH optional_remote_address_marker
        {
            // we accept an OPTIONAL 'remote address marker' as '/' (which is part of the path) at the end is good enough as a separator too
            $$ = $PATH;
        }

    | '(' URI ')' optional_remote_address_marker
        {
            $$ = $URI;
        }

    | '(' PATH ')' optional_remote_address_marker
        {
            $$ = $PATH;
        }

    | '[' URI ']' optional_remote_address_marker
        {
            // Excel way of referencing another workbook file...
            //
            // http://www.officetooltips.com/excel/tips/referencing_cells_outside_the_worksheet.html
            $$ = $URI;
        }

    | '[' PATH ']' optional_remote_address_marker
        {
            $$ = $PATH;
        }
    ;


optional_remote_address_marker
    : ε

    | remote_address_marker
    ;


remote_address_marker
    : '!'
    ;


fundamental_cell_reference
    : CELLREF
        {
            $$ = $CELLREF;
            parser.updateRangeLocationInfo($$, @CELLREF, +1);
        }
    ;


/*
 * See the section 'Notes on Ranges' near the top of this file: we support both 'fragmented' and 'regular' range
 * specifications here.
 */
any_range_reference
    : any_range_reference[first] ARRAY_CONCATENATION_OPERATOR any_range_reference[last]
        {
            /* a fragmented range, using alternative notation, i.e. this is equivalent to `{ any_range_reference , any_range_reference }` */
            //console.log("any_range_reference rule 1 :", @$);
            range = parser.mergeRanges($first, $last);
            parser.updateRangeLocationInfo(range, @$, +1);
            $$ = range;
        }

    | any_range_reference[left] ARRAY_CONCATENATION_OPERATOR error
        {
            rv = yy.parser.parseError("Expected a cell or range reference to complete the range.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            //console.log("any_range_reference rule 2 : error: ", @$);
            $$ = $left;
        }

    | single_range_reference_fragment
    ;


curlybraced_range_reference
    : '{'[open] ambiguous_any_range_reference '}'[close]
        {
            /*
             * A single range reference hiding in fragmented range notation or a fragmented range references with multiple curly braces surrounding it.
             *
             * We call the inner rule `**ambiguous_**any_range_reference` as it allows a cell range to be constructed
             * using ',' comma separated cell references, which as a notation is *ambiguous* when used in a function parameter list:
             * neither man nor machine will be able to identify which bits constitute a bundled range of cells and which items
             * are separate function arguments then if we do not use a bit of 'assistive' notation: the '{' '}' curly braces
             * which 'wrap' such an *ambiguous* range notation, e.g. `SUMPRODUCT({A1,A2,B1,B2},{C1,C2})`
             */
            range = $ambiguous_any_range_reference;
            parser.updateRangeLocationInfo(range, @$, +2);
            $$ = range;
        }
    ;


ambiguous_any_range_reference
    : ambiguous_any_range_reference[first] ',' ambiguous_any_range_reference[last]
        {
            /* a fragmented range: */
            //console.log("ambiguous_any_range_reference rule 1 :", @$);
            range = parser.mergeRanges($first, $last);
            parser.updateRangeLocationInfo(range, @$, +1);
            $$ = range;
        }

    | any_range_reference
        {
            /* a fragmented range, a cell reference or a regular range reference */
            $$ = $any_range_reference;
        }

    | cell_reference
        {
            /* a single cell reference, possibly acting as a range-of-one, depending on where this is used: */
            //console.log("ambiguous_any_range_reference rule 3 : cell: ", @$);
            range = parser.createRangeFromCell($cell_reference);
            parser.updateRangeLocationInfo(range, @$, +1);
            $$ = range;
        }

    | error
        {
            rv = yy.parser.parseError("Expected a (possibly fragmented) range reference.", {
                text: $error,
                token: $error,
                line: @error,
                loc: @error,
                outer_loc: @$,
                expected: [],
                recoverable: false
            });
            assert(rv === null);
            //console.log("ambiguous_any_range_reference rule 4 : error: ", @$);
            range = {
                rangeRef: null,
                locInfo: null,
                consumeCount: 0
            };
            parser.updateRangeLocationInfo(range, @$, 0);
            $$ = range;
        }
    ;


single_range_reference_fragment
    : range_reference
        {
            /* a regular range reference: */
            //console.log("range_reference rule 1 : range: ", @$);
            range = parser.createRangeFromRange($range_reference);
            parser.updateRangeLocationInfo(range, @$, +1);
            $$ = range;
        }

    | curlybraced_range_reference
        {
            /* a nested range reference which will be merged/flattened with any other cells / ranges in the outer range reference: */
            $$ = $curlybraced_range_reference;
        }
    ;



range_reference
    : RANGEREF
        {
            /*
             * > ### Note on cell reference order in a range
             * >
             * > we don't mind if 'first' is below or to the right of 'last'.
             * > The area is calculated in the action function where the range is used
             * > and there the row / col min and max values will be determined, so
             * > that we can use a simple and effective storage method here.
             * >
             * > Besides, the user might have a good reason to specify the range
             * > that way, so we better keep the first->last order as specified by
             * > the user to insure we can deliver expected behaviour (and not loose
             * > context information in the parse).
             */
            $$ = $RANGEREF;
            parser.updateRangeLocationInfo($$, @RANGEREF, +1);
        }
    ;











/*
 * Function call arguments
 * -----------------------
 *
 * Here we parse the argument lists of the function call in the formula, e.g. `=SUM(A1,A2,D7)`: `arglist = [A1,A2,D7]`
 */

one_argument
    : math_expression
        {
            $$ = [$math_expression];
        }

    | any_range_reference
        {
            // this still is a single function argument and should be identifiable as such:
            // hence the range specified as argument is stored into a single outer array entry here.
            //
            // Example to see the 'trouble': =MATCH(7,A1:A6,0): to properly feed MATCH() it should
            // receive 3 arguments: [1, [...], 0], where [...] is an ARRAY value listing the values
            // obtained from the range A1:A6, e.g. [3,4,5,6,7,8]
            //
            // WARNING: the current parser (the non-AST one!) always converts cell (and range) references
            // to values extremely quickly; this implies that functions such as ADDRESS() or INDEX() are
            // not supported as those require access to the actual cell references themselves.
            //
            // (Aside: of course we can be nasty and hack a cellref on top of a value as a JavaScript object attribute
            // but I'd rather not go there and do it properly with AST objects instead using the new parser...)
            //
            // Now for the slightly less positive news: =SUM(A1:A6) vs. =SUM(A1,A2,A3,A4,A5,A6) vs. =SUM(A1:A4,A5,A6):
            // all MUST deliver the same value due to the way SUM is meant to work, but these three will 'invoke'
            // the SUM() operator very differently: here are their arglist arrays: (assume A1=1, A2=2, ...)
            //
            //   =SUM(A1:A6)             : A1:A6             -> one_array_entry                           -> arglist = [[1,2,3,4,5,6]]
            //   =SUM(A1,A2,A3,A4,A5,A6) : A1,A2,A3,A4,A5,A6 -> one_element, one_element, ... (6x)        -> arglist = [1,2,3,4,5,6]
            //   =SUM(A1:A4,A5,A6)       : A1:A4,A5,A6       -> one_array_entry, one_element, one_element -> arglist = [[1,2,3,4],5,6]
            //
            // Now for the REAL trouble:
            //   =MATCH(7,A1:A6,0) (or any other Excel function that expects at least one other function parameter next to an array)
            //   -> do some projection or row insert/delete op in the grid: Visyond will 'service' you by rewriting the array TOKEN
            //      into an ARRAY of tokens. Great idea but you just lost everything as now the parameter list is ambiguous and cannot
            //      be resolved any more for such functions:
            //   -> drag/drop / insert row / other action that rewrites arrays in tokenarray
            //   -> =MATCH(7,A1,A2,A3,A4,A5,A6,0)
            //   -> OUCH! Nobody can tell us later on whether this is a user mistake feeding the function too many arguments or
            //      this being an expanded array in there. (Yes, there do exist Excel functions (Matrix ops!) which expect 2(!) or more
            //      array references as function arguments: when both are expanded (and they will), there is no telling where one
            //      ends and the next starts.)
            //   => Support for these functions (including SUMA(), SUMIF(), ...) is only possible when 'token stream rewriting' is heavily
            //      augmented and the parser is taught some additional notation as well (this is partly available in the AST grammar as
            //      it supports a superset of the Excel formula notation), e.g.
            //   =MATCH(7,A1:A6,0) -> tokenstream rewrite -> =MATCH(7,{A1,A2,A3,A4,A5,A6},0)
            //      or when expansion is done partially:
            //   =MATCH(7,A1:A6,0) -> tokenstream rewrite -> =MATCH(7,{A1,A2:A5,A6},0)
            //      With this 'extended' notation re-using the '{}' curly braces (also used by Excel for array formulas but we do not support those (yet))
            //      anything inside the curly braces is treated as part of a single array element:
            //   {A1,A2,A3,A4,A5,A6} is equivalent to {A1,A2:A5,A6} is equivalent to {A1:A6} is equivalent to A1:A6
            //
            // Anyhow, the above is NOT supported by this parser; only the AST parser provides for these constructs. The above explanation
            // is included here so y'all know what goes wrong and why...
            range = $any_range_reference;

            //patch_tokenstream("RANGEREF", range, 1 /* range.consumeCount */, @any_range_reference);

            /* This rule 'outputs' an array of values, each representing one cell value in the specified array */
            $$ = [parser.getArrayValueOfCellRangeSpec(range.rangeRef)];
        }

    | ε
        {
            /*
             * No argument specified at all: some functions accept this kind of behaviour.
             * It also serves as a way to specify a function with zero arguments, e.g.
             * `RANDOM()`.
             *
             * An empty argument is also legal as part of a larger argument set where *optional*
             * argument entries are accepted, e.g. `IF(A1,B1,)` or `LINEST(A1:A3,B1:B3,,1)`
             * hence we must push a special `nil` AST node for every empty argument.
             */

            // empty argument must take up a slot in the args array, hence we push NULL:
            $$ = [null];
        }
    ;


arglist
    : one_argument

    | arglist ','[comma] one_argument
        {
            $$ = $1.concat($3);
        }
    ;










/*
 * Percentages and other units of measure applied to numeric values
 * ----------------------------------------------------------------
 *
 * We allow users to input percentages, promilages, prodecamilages (~ `1 per 10K`), radians, degrees
 * and in any (predefined) currency.
 *
 * > ### Note about 'odd' percentage notation support
 * >
 * > Excel2010 accepts `%5` and `5%` as data entry of the _CELL VALUE_ `5%`, but you get an error when
 * > trying to enter the formula `=1+%5` while the formula `=1+5%` shows up as `105.00%` (+ formula, of course)
 */
percentage_alternative_for_data_entry
    : MODULO_OPERATOR value
        {
            // Excel supports percentage direct value entry as `%5` next to `5%`
            patch_tokenstream("PERCENTAGE_OPERATOR", null, 1, @MODULO_OPERATOR);
            $$ = $value / 100;
        }

    | PERCENTAGE_OPERATOR value
        {
            // Excel supports percentage direct value entry as `%5` next to `5%`
            $$ = $value / 100;
        }

    | PROMILAGE_OPERATOR value
        {
            $$ = $value / 1000;
        }
    ;


percentage
    : value PERCENTAGE_OPERATOR
        {
            $$ = $value / 100;
        }

    | value PROMILAGE_OPERATOR
        {
            $$ = $value / 1000;
        }
    ;


radians
    : value DEGREES_OPERATOR
        {
            // convert value to radians!
            $$ = $value * 2 * Math.PI / 360;
        }
    ;


price
    : CURRENCY value
        {
            /* The `CURRENCY` AST opcode has the notation attributes we need: */
            $$ = $value;
        }

    | value CURRENCY
        {
            $$ = $value;
        }
    ;


value
    : '-'[minus] number
        {
            $$ = -($number);
        }

    | '+'[plus] number
        {
            $$ = +($number);
        }

    | INTEGER_NUMBER '!'[facult]
        {
            $$ = (function fact(n) {
                return n == 0 ? 1 : fact(n - 1) * n;
            })($INTEGER_NUMBER);
        }

    | number
    ;


number
    : NUMBER
        {
            assert($NUMBER === yytext);
            assert(typeof $NUMBER === 'number');
            $$ = $NUMBER;
        }

    | INTEGER_NUMBER
        {
            assert($INTEGER_NUMBER === yytext);
            assert(typeof $INTEGER_NUMBER === 'number');
            $$ = $INTEGER_NUMBER;
        }
    ;


constant
    : CONSTANT

    | '-'[minus] CONSTANT
        {
            $$ = -($CONSTANT);
        }

    | '+'[plus] CONSTANT
        {
            $$ = +($CONSTANT);
        }
    ;


boolean
    : TRUE

    | FALSE
    ;


string
    : STRING
    ;






/*
 * And we end it all on a light note: this is a dummy 'collect all tokens' rule so that I can be sure that JISON compiles
 * all them buggers to numeric values.
 */
Ill_be_boogered
    : EOF error error error '!' '$' '(' ')' '*' '+' ',' '-' '.' '/' ':' '<' '=' '>' '?' '@' '[' ']' '^' '{' '}'
    ;









/*
 * And here endeth the parser proper
 * ---------------------------------
 *
 * This concludes the grammar rules definitions themselves.
 * What follows is a chunk of support code that JISON will include in the generated parser.
 */


%%










/*
 * This chunk is included in the parser object code,
 * following the 'init' code block that may be set in `%{ ... %}` at the top of this
 * grammar definition file.
 */



parser.createRangeFromRange = function (rangeref) {
    return {
        rangeRef: [rangeLabelWithDollarToRowColWorkbook(rangeref)],
        locInfo: null,
        consumeCount: 0
    };
};

parser.createRangeFromCell = function (cellref) {
    var coord = cellLabelWithDollarToRowColWorkbook(cellref);
    assert(coord);
    return {
        rangeRef: [{
            row: coord.row,
            row2: coord.row,
            col: coord.col,
            col2: coord.col,
            workbookIndex: coord.workbookIndex
        }],
        locInfo: null,
        consumeCount: 0
    };
};

parser.updateRangeLocationInfo = function (range, locInfo, consumeCount) {
    if (!range.locInfo) {
        range.locInfo = locInfo;
        assert(range.consumeCount === 0);
    } else {
        if (range.locInfo.last_line < locInfo.last_line || (range.locInfo.last_line === locInfo.last_line && range.locInfo.last_column < locInfo.last_column)) {
            range.locInfo.last_line = locInfo.last_line;
            range.locInfo.last_column = locInfo.last_column;
            if (locInfo.range) {
                assert(range.locInfo.range);
                assert(range.locInfo.range[1] <= locInfo.range[1]);
                assert(range.locInfo.range[1] <= locInfo.range[0]);
                range.locInfo.range[1] = locInfo.range[1];
            }
        }
        if (range.locInfo.first_line > locInfo.first_line || (range.locInfo.first_line === locInfo.first_line && range.locInfo.first_column > locInfo.first_column)) {
            range.locInfo.first_line = locInfo.first_line;
            range.locInfo.first_column = locInfo.first_column;
            if (locInfo.range) {
                assert(range.locInfo.range);
                assert(range.locInfo.range[0] <= locInfo.range[0]);
                assert(range.locInfo.range[1] <= locInfo.range[0]);
                range.locInfo.range[0] = locInfo.range[0];
            }
        }
    }
    range.consumeCount += consumeCount;
};

parser.mergeRanges = function (range1, range2) {
    assert(range1);
    assert(range2);
    range1.rangeRef = range1.rangeRef.concat(range2.rangeRef);
    this.updateRangeLocationInfo(range1, range2.locInfo, range2.consumeCount);
    return range1;
};

//e.g., gets {B4:A2,C7} and returns the values of [A2,B2,A3,B3,A4,B4,C7]
//e.g., Revenues[2011]:Revenues[2014], transforms into an array Cell IDs (e.g., [A2,B2,C2,D2]) and returns the values of the cells in the array
//
//Note: user can type B4:A2
parser.getArrayValueOfCellRangeSpec = function (rangeSpec) {
    // In order to prevent double references in the range spec to be executed twice or more, we first collect
    // the set of referenced cells:
    var collection = new Uint8ClampedArray(MAX_GRID_ROW * MAX_GRID_COL);
    var rangesize = 0;
    for (var k = 0, len = rangeSpec.length; k < len; k++) {
        var spec = rangeSpec[k];
        rangesize += (spec.row2 - spec.row + 1) * (spec.col2 + spec.col + 1);
    }
    var values = new Array(rangesize);
    var valindex = 0;
    for (var k = 0, len = rangeSpec.length; k < len; k++) {
        var spec = rangeSpec[k];
        //create the array of cells
        for (var i = spec.row; i <= spec.row2; i++) {
            var rowstep = i * MAX_GRID_COL;
            for (var j = spec.col; j <= spec.col2; j++) {
                var cellRef = j + rowstep;
                if (!collection[cellRef]) {
                    collection[cellRef] = 1;
                    spec.workbookIndex = spec.workbookIndex || getImplicitWBIdx();
                    assert(spec.workbookIndex);
                    values[valindex++] = getCellValueByRowColWS(i, j, spec.workbookIndex);
                }
            }
        }
    }
    // and redimension the array once so that the receiver gets a nice, clean, array of cell values.
    values.length = valindex;
    return values;
};






/*
 * Return TRUE if all AST nodes in the arglist collection (an array) are constants.
 *
 * Otherwise return FALSE.
 */
parser.isEntireArgListConstant = function (arglist) {
    var i,
        l = arglist.length;
    for (i = 0; i < l; l++) {
        if (!arglist[i].constant) {
            return false;
        }
    }
    return true;
};


/*
 * Return the UNIT of the arglist collective: when all have the same UNIT, it is that.
 *
 * Otherwise it is `FU_ANY` as we cannot say how these AST nodes combine (`SUM`/`AVG`/`MULTIPLY`/...).
 */
parser.determineArgListUnit = function (arglist) {
    var i, u, l = arglist.length;
    if (!l) {
        return FU_ANY;
    }
    u = arglist[0].unit;
    for (i = 1; i < l; l++) {
        if (arglist[i].unit != u) {
            return FU_ANY;
        }
    }
    return u;
};


/*
 * Decode cell references such as `A5` when these are entered in input fields, etc.
 *
 * This performs a regular parse and then makes sure that the parsed 'formula' is actually
 * a single, valid, cell reference and returns the corresponding AST object.
 *
 * When the entered content is NOT a valid cell reference, an exception (error message) is thrown.
 */
parser.parseCellReference = function (input) {
    this.parse_mode = FPM_CELLREF;
    var ast;

    try {
        ast = this.parse(input);
    }
    finally {
        this.parse_mode = FPM_FORMULA;
    }

    if (typeof ast !== "undefined" && ast.opcode == FKW_CELLREF) {
        return ast;
    }

    throw new Error(input + " is not a valid cell reference");
};


/*
 * Decode cell range references such as `A5:C7` when these are entered in input fields, etc.
 *
 * This performs a regular parse and then makes sure that the parsed 'formula' is actually
 * a single, valid, range reference and returns the corresponding AST object.
 *
 * When the entered content is NOT a valid range reference, an exception (error message) is thrown.
 */
parser.parseRangeReference = function (input) {
    this.parse_mode = FPM_RANGEREF;
    var ast;

    try {
        ast = this.parse(input);
    }
    finally {
        this.parse_mode = FPM_FORMULA;
    }

    if (typeof ast !== "undefined" && ast.opcode == FKW_RANGEREF) {
        return ast;
    }

    throw new Error(input + " is not a valid range reference");
};


/*
 * Decode the input expression and 'fold' it into a single value, i.e. calculate its present value.
 *
 * This performs a regular parse and then makes sure that the parsed 'formula' is 'folded'
 * into a single (numeric / string / boolean) value and returns the corresponding AST object.
 *
 * When the entered content is NOT a valid immediate value expression, an exception (error message) is thrown.
 */
parser.parseValue = function (input) {
    this.parse_mode = FPM_IMMEDIATE_VALUE;
    var ast;

    try {
        ast = this.parse(input);
    }
    finally {
        this.parse_mode = FPM_FORMULA;
    }

    if (typeof ast !== "undefined" && ast.opcode == FKW_VALUE) {
        return ast;
    }

    throw new Error(input + " is not a valid value expression");
};


/*
 * Remove duplicated quotes (of the form `quote_str + quote_str`, e.g. `""`) from the input string.
 */
parser.dedupQuotedString = function (str, quote_str) {
    return str.replace(quote_str + quote_str, quote_str);
};


// Would it be a viable basic column identifier?
parser.isValidColumnID = function (s) {
    var col;
    var match;

    if (s.length <= MAX_GRID_COL_ID_LENGTH) {
        s = s.toUpperCase();
        match = s.match(/^[A-Z]+$/);
        if (match) {
            // check if this is a legal column id:
            col = colLetterToNumber(s);
            assert(col === false || assertGraphCol(col));
            if (col >= 1 && col <= MAX_GRID_COL) {
                return col;
            }
        }
    }
    return false;
};


// Would it be a viable basic row identifier?
parser.isValidRowID = function (s) {
    var row;
    var match;

    if (s.length <= MAX_GRID_ROW_ID_LENGTH) {
        s = s.toUpperCase();
        match = s.match(/^[0-9]+$/);
        if (match) {
            // check if this is a legal column id:
            row = parseInt(s);
            if (row >= 1 && row <= MAX_GRID_ROW) {
                return row;
            }
        }
    }
    return false;
};




// Would it be a viable cell reference?
parser.isValidCellRef = function (s) {
    var rv = cellLabelWithDollarToRowColWorkbook(s, {
        fireEventOnError: false
    });
    return rv;
};




// Would it be a viable cell range reference?
parser.isValidCellRange = function (s) {
    var rv = rangeLabelWithDollarToRowColWorkbook(s, {
        fireEventOnError: false
    });
    return rv;
};



/*
 * Return the definition structure for the given symbol name, or FALSE when the symbol is unknown.
 *
 * The definition structure contains these elements:
 *
 * - token
 * - defined_value
 */

parser.getSymbol4Function = function (name) {
    name = name.toUpperCase();
    assert(this._symbol2token_lookup_table);
    assert(this._symbol2token_lookup_table.functions);
    var rv = this._symbol2token_lookup_table.functions[name];
    if (rv && rv.quality < vUserPreferences.quality) {
        return false;
    }
    return rv || false;
};

parser.getSymbol4DefinedConstant = function (name, mandatory_category_bits) {
    mandatory_category_bits |= 0;
    name = name.toUpperCase();
    assert(this._symbol2token_lookup_table);
    assert(this._symbol2token_lookup_table.constants);
    var rv = this._symbol2token_lookup_table.constants[name];
    if (rv && rv.quality < vUserPreferences.quality) {
        return false;
    }
    if (rv && (rv.category & mandatory_category_bits) !== mandatory_category_bits) {
        return false;
    }
    return rv || false;
};

parser.getSymbol4Currency = function (name) {
    name = name.toUpperCase();
    assert(this._symbol2token_lookup_table);
    assert(this._symbol2token_lookup_table.currencies);
    var rv = this._symbol2token_lookup_table.currencies[name];
    if (rv && rv.quality < vUserPreferences.quality) {
        return false;
    }
    /*
     * output structure:
     *
     * - notation: FKA constant
     * - prefix:   string (optional; required for currencies which are not hard-coded FKA notation constants)
     */
    return rv || false;
};

parser.getJSONfilterSymbol = function (name) {
    name = name.toUpperCase();
    assert(this._symbol2token_lookup_table);
    assert(this._symbol2token_lookup_table.json_filter_functions);
    var rv = this._symbol2token_lookup_table.json_filter_functions[name];
    return rv || false;
};

parser.getSymbol4RowOrColumnName = function (name) {
    var rv = this.getSymbol4RowName(name);
    if (!rv) {
        rv = this.getSymbol4ColumnName(name);
        if (rv) {
            assert(rv.col >= 1);
            assert(rv.provides === NRA_COLUMN);
            return rv;
        }
        return false;
    } else {
        assert(rv.row >= 1);
        assert(rv.provides === NRA_ROW);
        return rv;
    }
};

parser.getSymbol4RowName = function (name) {
    var rv = vGraph.getRowOfLabel(name);
    if (rv) {
        return {
            row: rv,
            provides: NRA_ROW
        };
    }
    return false;
};

parser.getSymbol4ColumnName = function (name) {
    var rv = vGraph.getColOfLabel(name);
    if (rv) {
        return {
            col: rv,
            provides: NRA_COLUMN
        };
    }
    return false;
};

parser.getSymbol4CellRef = function (name) {
    var rv = vGraph.getCellOfLabel(name);
    if (rv) {
        return {
            col: rv.col,
            row: rv.row,
            provides: NRA_COLUMN | NRA_ROW
        };
    }
    return false;
};


/*
 * Initialize the symbol lookup tables.
 */
parser.initSymbolTable = function (custom_symbols) {
    this._symbol2token_lookup_table = {
        functions: {},                  // hash table ~ dictionary
        constants: {},                  // hash table ~ dictionary
        currencies: {},                 // hash table ~ dictionary
        json_filter_functions: {}       // hash table ~ dictionary
    };

    // first set up the default symbols: constants, etc.; once that is done, register the custom symbols:
    this.addSymbols(get_predefined_formula_constants(), FSC_PREDEFINED_CONSTANT);
    this.addSymbols(get_predefined_formula_currencies(), FSC_CURRENCY);
    this.addSymbols(get_predefined_formula_functions(), FSC_FUNCTION);

    return this.addSymbols(custom_symbols);
};


/*
 * Register one or more symbols in the symbol lookup tables:
 */
parser.addSymbols = function (symbols, default_category) {
    var s, category, name, done, node, alts, k;

    for (var i = 0, len = symbols.length; i < len; i++) {
        s = symbols[i];

        // ignore symbols which are not enabled / suitable for the current quality level:
        if (s.quality < vUserPreferences.quality) {
            continue;
        }

        category = s.category || default_category;
        done = 0;
        if (category & FSC_FUNCTION) {
            alts = s.alts || [];
            alts.push(String(s.name).toUpperCase());
            for (k in alts) {
                this._symbol2token_lookup_table.functions[alts[k]] = s;
            }
            ++done;
        }
        if (category & FSC_PREDEFINED_CONSTANT) {
            alts = s.alts || [];
            alts.push(String(s.name).toUpperCase());
            for (k in alts) {
                this._symbol2token_lookup_table.constants[alts[k]] = s;
            }
            ++done;
        }
        if (category & FSC_CURRENCY) {
            alts = s.alts || [];
            alts.push(String(s.name).toUpperCase());
            for (k in alts) {
                this._symbol2token_lookup_table.currencies[alts[k]] = s;
            }
            ++done;
        }
        if (category & FSC_CELL_LABEL) {
            vGraph.setCellLabel(s.col, s.row, s.name);
            ++done;
        }
        if (category & FSC_COLUMN_LABEL) {
            vGraph.setColLabel(s.col, s.name);
            ++done;
        }
        if (category & FSC_ROW_LABEL) {
            vGraph.setRowLabel(s.row, s.name);
            ++done;
        }
        if (category & FSC_JSON_FILTER_FUNCTION) {
            alts = s.alts || [];
            alts.push(String(s.name).toUpperCase());
            for (k in alts) {
                this._symbol2token_lookup_table.json_filter_functions[alts[k]] = s;
            }
            ++done;
        }
        if (category & FSC_CELL_VALUE_PRESET) {
            // WARNING: this category is really here to assist the unit tests; in actual use, this is never expected to be invoked!
            node = vGraph.createBlankNode(s.row, s.col);
            assert(node, "Old vs New: createBlankNode does not always create node anymore when collaborator");

//            node.formula = "" + s.value;
            node.value = s.value;
            vProject.addNode(node, node.value);
            ++done;
        }
        if (!done) {
            //console.log("symbol [" + s.name + "] does not belong in any category: ", i, s, category);
            throw new Error("symbol [" + s.name + "] does not belong in any category");
        }
    }
    return this;
};




/*
 * Store the current comment which has terminated and needs to be stored until the next token is produced by the lexer.
 */
parser.pushComment = function () {
    var lexer = this.lexer;

    // a la pastInput():
    var past = lexer.matched.substr(0, this.matched.length - this.match.length);
    var startloc = lexer.inline_comment_start_yylloc.ranges[1]; // pick the offset beyond the comment-start marker!
    past = past.substr(startloc);
    // strip surrounding whitespace:
    // http://jsperf.com/javascript-trim-string/2
    past = past.trim();

    var node = new Visyond.FormulaParser.inlineComment(FKW_INLINE_COMMENT, lexer.inline_comment_start_yylloc, past);
    this.comments.push(node);
    return this;
};


/*
 * Return the array of comments when there are any, otherwise return FALSE.
 *
 * Also empty the comment store.
 */
parser.popComments = function () {
    var rv = this.comments;
    this.clearComments();
    if (typeof rv !== "undefined" && rv.length > 0) {
        return rv;
    } else {
        return false;
    }
};


/*
 * Clear / (re-)initialize the comments' store.
 */
parser.clearComments = function () {
    this.comments = [];
    return this;
};


/*
 * Return the index to the next available slot in the comment store.
 *
 * Consequently returns 0 when the comment store is empty.
 */
parser.getNextCommentIndex = function () {
    var rv = this.comments;
    if (typeof rv !== "undefined" && rv.length > 0) {
        return rv.length;
    } else {
        return 0;
    }
};


parser.pre_parse = function (yy) {
    //console.log("parser init", this, arguments);

    /*
     * The 'init phase' is always invoked for every parse invocation.
     *
     * At this point in time, nothing has happened yet: no token has
     * been lexed, no real statement has been parsed yet.
     *
     * Incidentally, we also use this moment in time to reset the
     * 'inline comments' monitor: depending on the `options.inline_comments_mode`
     * setting do we allow inline comments
     *
     *  - always,
     *  - only after the "=" starting the formula, or
     *  - never
     *
     * The grammar has been constructed such that this rule can be
     * resolved without any look-ahead, thanks to a 'default action'.
     */
    //yy.lexer.options.backtrack_lexer = true;
    //yy.lexer.options.ranges = true;             // required for the inline comments to work as the start location is tracked via the `yylloc.range[]`
    yy.lexer.options.inline_comment_mode = yy.inline_comment_mode | 0;

    if (yy.lexer.options.inline_comment_mode < 2) {
        yy.lexer.inline_comments_monitor = 0; // for `mode=1` comment support will be enabled as soon as we encounter a `=`
    } else {
        yy.lexer.inline_comments_monitor = yy.lexer.options.inline_comment_mode + 1;
    }

    // and make sure the comments store is prepped:
    yy.parser.clearComments();

    // and init the symbol tables if the caller didn't do so already (we do this in order to prevent undesirable crashes)
    if (typeof yy.parser._symbol2token_lookup_table === "undefined") {
        yy.parser.initSymbolTable([]);
    }

    /*
     * Depending on parser mode we must push a 'magick marker' into the lexer stream
     * which is a hack offering a working alternative to having the parser generator
     * support multiple %start rules.
     */
    yy.lexer.pushState('PARSE_MODE_DETECTION');
    switch (yy.parser.parser_mode) {
    default:
        break;

    case FPM_CELLREF:
        yy.lexer.unput("\u0001");
        break;

    case FPM_RANGEREF:
        yy.lexer.unput("\u0002");
        break;

    case FPM_IMMEDIATE_VALUE:
        yy.lexer.unput("\u0003");
        break;
    }
};







// Return FALSE on success, return object containing both index number of argument which mismatched the spec + minimal error report
//
// break_on_severity_level: when set, it determines whether this validation function will break on the first WARNING (-1/false) or ERROR (+1/true)
parser.passingArgumentSetValidation = function (opcode, args_array, break_on_severity_level) {
    // opcode is a reference to the object

    break_on_severity_level |= 0;
    break_on_severity_level--;          // FALSE --> -1 // TRUE --> 0

    // console.log("opcode.parameter_set_definition from passingArgumentSetValidation: ",opcode.parameter_set_definition);
    // console.log("args_array from passingArgumentSetValidation: ",args_array);

    var arg_def_set = opcode.parameter_set_definition;
    var alen, dlen, ai, di, dt, at, i;
    var basic_type, dotdotdot, coerce;
    var oki;

    alen = args_array.length;
    dlen = arg_def_set.length;

    // example: [FAX_NUMBER | FAX_COERCE | FAX_DOTDOTDOT]

    // check each incoming argument against the function interface specification:
    di = 0;
    for (ai = 0; ai < alen; ai++) {
        if (di >= dlen) {
            // We ran out of argument specs early: apparently we received more function arguments than is legally allowed!
            return {
                severity: 1,         // ERROR > 0
                index: ai,
                spec_index: di,
                spec_bits: null,
                is_user_failure: true,
                message: "Argument #" + (ai + 1) + " is superfluous and ignored by the function"
            };
        }
        dt = arg_def_set[di]; // FAX_... bits defining the expected argument type.
        // extract basic type and option bits:
        basic_type = (dt & FAX_ANY);
        optional = (dt & FAX_OPTIONAL);
        dotdotdot = (dt & FAX_DOTDOTDOT);
        coerce = (dt & FAX_COERCE);

        at = typeof args_array[ai];
        // TODO: fix this code so it works out for COUNTIF() et al: those have FAX_DOTDOTDOT followed by 'trailing' argument(s) in the spec!
        /*
         * Nasty: two ways to invoke COUNTIF() et al as Excel formula expressions:
         *
         * **Edit: NOT TRUE -- > EXCEL DOES NOT ALLOW TO INVOKE THEM LIKE THE BELOW, ONLY RANGE AND CONDITION**
         *
         * =COUNTIF(A1, A2, A3, A4, A5, ">0");
         * -->
         * =COUNTIF(1, 2, 3, 4, 5, ">0");
         * i.e. args_array.length = 6
         *
         * =COUNTIF(A1:A5, ">0");
         * -->
         * =COUNTIF([1, 2, 3, 4, 5], ">0");
         * i.e. args_array.length = 2
         */

        di++;

        if (dotdotdot) {
            // when the spec announces it expects an arbitrary number of arguments like this one,
            // we do NOT increment the spec index as the next argument must be matched against the same
            // spec entry.
            di--;
        }

        if (optional) {
            // argument is allowed to not be present, i.e. may be undefined/null(=empty). E.g. 2nd arg for "IF(cond,,false_value)"
            if (at === 'undefined' || args_array[ai] === null) {
                continue;
            }
        }
        // when the spec announces the argument will be coerced to some type(s), we currently accept ANYTHING!
        if (coerce) {
            continue;
        }
        // when the argument may be anything, we're down with that too!
        if (basic_type === FAX_ANY) {
            continue;
        }

        // basic_type is a bitfield itself, so check argument type against the bits:
        switch (at) {
        case 'undefined':
            // that's unexpected: we only get here when the argument is NOT OPTIONAL.
            // ... and 'undefined' is NOT identical to 'empty' ...
            return {
                severity: 1,         // ERROR > 0
                index: ai,
                spec_index: di,
                spec_bits: dt,
                is_user_failure: false,
                message: "Argument #" + (ai + 1) + " is unexpectedly empty/undefined; was expecting " + parser.describeFAXbits(dt)
            };

        case 'boolean':
            if (!(basic_type & FAX_BOOLEAN)) {
                oki = {
                    severity: -1,         // WARNING < 0
                    index: ai,
                    spec_index: di,
                    spec_bits: dt,
                    is_user_failure: false,
                    message: "Argument #" + (ai + 1) + " is a boolean, which will not be coerced; was expecting " + parser.describeFAXbits(dt)
                };
                if (break_on_severity_level <= oki.severity) return oki;
            }
            continue;

        case 'string':
            if (!(basic_type & FAX_STRING)) {
                // When we don't accept a string input, we may still accept something similar: a DATE
                // (Side note: we 'know' that FAX_COMPLEX_NUMBER = FAX_STRING so we don't go and check for FAX_COMPLEX_NUMBER separately here!)
                if (!(basic_type & FAX_DATE)) {
                    oki = {
                        severity: -1,         // WARNING < 0
                        index: ai,
                        spec_index: di,
                        spec_bits: dt,
                        is_user_failure: false,
                        message: "Argument #" + (ai + 1) + " is a string, which will not be coerced; was expecting " + parser.describeFAXbits(dt)
                    };
                    if (break_on_severity_level <= oki.severity) return oki;
                }
                // When we allow a date, we now assume ANY string will correctly coerce into a valid date.
                // We do know this is a very fast and off-handed (and WRONG) approach, but we want speed over accuracy for now...
            }
            continue;

        case 'number':
            if (!(basic_type & FAX_NUMBER)) {
                // When we don't accept a numeric input, we may still accept something similar: a DATE
                if (!(basic_type & FAX_DATE)) {
                    oki = {
                        severity: -1,         // WARNING < 0
                        index: ai,
                        spec_index: di,
                        spec_bits: dt,
                        is_user_failure: false,
                        message: "Argument #" + (ai + 1) + " is a number, which will not be coerced; was expecting " + parser.describeFAXbits(dt)
                    };
                    if (break_on_severity_level <= oki.severity) return oki;
                }
                // When we allow a date, we now assume ANY number will correctly coerce into a valid date.
                // We do know this is a very fast and off-handed (and WRONG) approach, but we want speed over accuracy for now...
            }
            continue;

        default:
            // If the given argument is an array or NULL we arrive here.
            // NULL **MAY** be a result from an earlier parse error (#VALUE or some such, maybe?)
            // so we need to differentiate between NULL and 'the rest of 'em':
            if (args_array[ai] === null) {
                if (!(basic_type & FAX_VOID)) {
                    // This is pretty darn illegal as it's the same to us as 'undefined':
                    return {
                        severity: 1,         // ERROR > 0
                        index: ai,
                        spec_index: di,
                        spec_bits: dt,
                    is_user_failure: false,
                        message: "Argument #" + (ai + 1) + " is null/empty/undefined; was expecting " + parser.describeFAXbits(dt)
                    };
                } else {
                    // This function accepts a `(void)` parameter, i.e. this function accepts *zero* arguments:
                    assert(ai === 0);
                    assert(alen === 1);
                    continue;
                }
            }
            // 'the rest of 'em': RANGEREF, CELLREF, etc. will only show up as-is in the AST grammar;
            // here they have been 'expanded' in value arrays already.
            // For simplicity, we simply accept any of those when the function argument is an array/object/non-basic-JS-type:
            if (!(basic_type & (FAX_DATASET | FAX_COLREF | FAX_ROWREF | FAX_CELLREF | FAX_RANGEREF))) {
                oki = {
                    severity: -1,         // WARNING < 0
                    index: ai,
                    spec_index: di,
                    spec_bits: dt,
                    is_user_failure: false,
                    message: "Argument #" + (ai + 1) + " is of incorrect type; was expecting " + parser.describeFAXbits(dt)
                };
                if (break_on_severity_level <= oki.severity) return oki;
            }
            continue;
        }
    }

    if (di < dlen) {
        // Fewer arguments were passed than strictly required. Or is it? (FAX_OPTIONAL / FAX_DOTDOTDOT)
        //
        // It is only OKAY when
        // - ALL missing arguments are FAX_OPTIONAL
        // - this argument is FAX_DOTDOTDOT **AND** no further 'trailing' arguments are expected (COUNTIF()!!!)

        dt = arg_def_set[di]; // FAX_... bits defining the expected argument type.
        // extract basic type and option bits:
        basic_type = (dt & FAX_ANY);
        optional = (dt & FAX_OPTIONAL);
        dotdotdot = (dt & FAX_DOTDOTDOT);
        coerce = (dt & FAX_COERCE);

        if (optional) {
            // We MAY omit this argument, but then we should also be allowed to omit the subsequent ones,
            // otherwise this FAX_OPTIONAL would've been caught inside the for() loop above!
            for (i = di + 1; i < dlen; i++) {
                if (!(arg_def_set[i] & FAX_OPTIONAL)) {
                    // any NON-optional argument following us means we are at fault already!
                    return {
                        severity: 1,         // ERROR > 0
                        index: ai,
                        spec_index: i,
                        spec_bits: arg_def_set[i],
                        is_user_failure: true,
                        message: "Incorrect number of arguments; you did not specify a required argument"
                    };
                }
            }
            // It turns out this argument and all following it are optional, so we're good to go!
        } else if (dotdotdot) {
            // no more /specified/ arguments after this one allowed, because we don't have any more to offer!
            if (di + 1 < dlen) {
                return {
                    severity: 1,         // ERROR > 0
                    index: ai,
                    spec_index: di,
                    spec_bits: dt,
                    is_user_failure: true,
                    message: "Incorrect number of arguments; you did not specify the trailing arguments"
                };
            }
            // We're the last spec entry, so we're good to go!
        } else {
            // We have checked all given function arguments, yet still have some unmatched argument specs, which are NON-OPTIONAL.
            // This means the user didn't provide all the required arguments!
            return {
                severity: 1,         // ERROR > 0
                index: ai,
                spec_index: di,
                spec_bits: dt,
                is_user_failure: true,
                message: "Incorrect number of arguments; you did not specify one or more required arguments"
            };
        }
    }

    return false;
};


parser.describeFAXbits = function (t) {
    var s, b, v, d, c, o;

    t |= 0;
    b = (t & FAX_ANY);
    v = (t & FAX_VOID);
    o = (t & FAX_OPTIONAL);
    c = (t & FAX_COERCE);
    d = (t & FAX_DOTDOTDOT);

    if (b === FAX_ANY) {
        s = "(anything)";
    } else if (v) {
        s = "(void)";
    } else {
        assert(b != 0);
        s = "(";
        if (b & FAX_NUMBER) {
            s += "number";
        }

        // tricky: we 'know' the FAX_COMPLEX_NUMBER only shows up in the spec when it is FAX_NUMBER | FAX_COMPLEX_NUMBER, i.e. FAX_NUMBER | FAX_STRING:
        if ((FAX_NUMBER | FAX_STRING | FAX_COMPLEX_NUMBER) === (b & (FAX_NUMBER | FAX_STRING | FAX_COMPLEX_NUMBER))) {
            if (s) s += ",";
            s += "complex";
        }

        if (b & FAX_DATE) {
            if (s) s += ",";
            s += "date";
        }
        if (b & FAX_BOOLEAN) {
            if (s) s += ",";
            s += "boolean";
        }
        if (b & FAX_STRING) {
            if (s) s += ",";
            s += "string";
        }
        if (b & FAX_DATASET) {
            if (s) s += ",";
            s += "dataset";
        }
        if (b & FAX_COLREF) {
            if (s) s += ",";
            s += "columnREF";
        }
        if (b & FAX_ROWREF) {
            if (s) s += ",";
            s += "rowREF";
        }
        if (b & FAX_CELLREF) {
            if (s) s += ",";
            s += "cellREF";
        }
        if (b & FAX_RANGEREF) {
            if (s) s += ",";
            s += "rangeREF";
        }

        s += ")";
    }

    if (c) {
        s += "*";
    }

    if (d) {
        s += "...";
    }

    if (o) {
        s = "[" + s + "]";
    }

    return s;
};
